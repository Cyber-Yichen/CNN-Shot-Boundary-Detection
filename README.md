# ğŸ¬ CNN-Shot-Boundary-Detection

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-2.0+-red.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/Platform-Linux%20%7C%20Windows%20%7C%20macOS-lightgrey.svg" alt="Platform">
</p>

A lightweight CNN-based system for automatic shot boundary detection in videos, designed for efficient training, evaluation, and integration into computational film analysis and intelligent editing workflows.

åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„è½»é‡çº§è§†é¢‘é•œå¤´è¾¹ç•Œæ£€æµ‹ç³»ç»Ÿï¼Œä¸“ä¸ºè®¡ç®—ç”µå½±åˆ†æå’Œæ™ºèƒ½å‰ªè¾‘å·¥ä½œæµè®¾è®¡ã€‚

---

## ğŸ“– Table of Contents

- [Features](#-features)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Model Architecture](#-model-architecture)
- [Training](#-training)
- [Evaluation Metrics](#-evaluation-metrics)
- [Tools](#-tools)
- [License](#-license)

---

## âœ¨ Features

- ğŸš€ **Multiple Model Architectures**: CNN, MLP, and Linear models for comparison
- ğŸ“Š **Multi-Channel Input**: Support for 9-channel (2FPS) and 21-channel (4FPS) inputs
- âš–ï¸ **Class Imbalance Handling**: Weighted loss function with configurable pos_weight
- ğŸ“ˆ **Comprehensive Metrics**: Precision, Recall, F1, PR-AUC, ROC-AUC, and per-video analysis
- ğŸ› ï¸ **Complete Toolchain**: Dataset creation, training, evaluation, and report visualization
- ğŸŒ **Web-based Tools**: Flask and Streamlit applications for data preparation and result viewing

---

## ğŸ“ Project Structure

```
CNN-Shot-Boundary-Detection/
â”œâ”€â”€ Dataset Tool/           # Dataset creation tool (Flask)
â”‚   â”œâ”€â”€ app.py              # Main Flask application
â”‚   â””â”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ Movie Cut/              # Video frame extraction tool (Streamlit)
â”‚   â”œâ”€â”€ movie.py            # Frame sampler application
â”‚   â””â”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ Reports System/         # Training report visualization (Flask)
â”‚   â”œâ”€â”€ app.py              # Report viewer application
â”‚   â”œâ”€â”€ rsys/               # Report system modules
â”‚   â””â”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ Traning Files/          # Training notebooks and code
â”‚   â”œâ”€â”€ CNN_2FPS_9CH.ipynb  # CNN model with 9-channel input
â”‚   â”œâ”€â”€ CNN_4FPS_21CH.ipynb # CNN model with 21-channel input
â”‚   â”œâ”€â”€ MLP_2FPS_9CH.ipynb  # MLP model with 9-channel input
â”‚   â”œâ”€â”€ MLP_4FPS_21CH.ipynb # MLP model with 21-channel input
â”‚   â”œâ”€â”€ Linear_2FPS_9CH.ipynb   # Linear model with 9-channel input
â”‚   â”œâ”€â”€ Linear_4FPS_21CH.ipynb  # Linear model with 21-channel input
â”‚   â”œâ”€â”€ code/               # Additional training code
â”‚   â””â”€â”€ movie/              # Video dataset directory
â”œâ”€â”€ Traning Reports/        # Generated training reports
â””â”€â”€ LICENSE                 # MIT License
```

---

## ğŸ”§ Installation

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (recommended)

### Install Dependencies

```bash
# Clone the repository
git clone https://github.com/Cyber-Yichen/CNN-Shot-Boundary-Detection.git
cd CNN-Shot-Boundary-Detection

# Install core dependencies
pip install torch torchvision
pip install opencv-python numpy openpyxl

# For Dataset Tool
pip install flask

# For Movie Cut
pip install streamlit

# For Reports System
pip install flask openpyxl
```

---

## ğŸš€ Quick Start

### 1. Prepare Dataset

Use the **Movie Cut** tool to extract frames from videos:

```bash
cd "Movie Cut"
streamlit run movie.py
```

### 2. Create Training Data

Use the **Dataset Tool** to generate cut/non-cut samples:

```bash
cd "Dataset Tool"
python app.py
```

### 3. Train Model

Open the Jupyter notebook and run training:

```bash
cd "Traning Files"
jupyter notebook CNN_2FPS_9CH.ipynb
```

### 4. View Results

Launch the **Reports System** to visualize training metrics:

```bash
cd "Reports System"
python app.py
```

---

## ğŸ—ï¸ Model Architecture

### BoundaryCNN

The core CNN model uses a simple yet effective architecture:

```python
class BoundaryCNN(nn.Module):
    def __init__(self):
        super(BoundaryCNN, self).__init__()  
        self.features = nn.Sequential(
            nn.Conv2d(9, 32, kernel_size=3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
        )  
        self.classifier = nn.Sequential(
            nn.Linear(64 * 28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 2)  # Binary: Cut / Non-Cut
        )
```

### Input Construction

| Mode | Channels | Description |
|------|----------|-------------|
| **2FPS - 9CH** | 9 | `[Frame_A (3)] + [Frame_B (3)] + [Diff (3)]` |
| **4FPS - 21CH** | 21 | Multiple consecutive frames with differences |

The model takes concatenated adjacent frames and their pixel-wise difference as input to detect shot boundaries.

---

## ğŸ¯ Training

### Configuration

Key hyperparameters in the training notebooks:

```python
# Data settings
DATA_VERSION = "v13"
FRAME_SIZE = (224, 224)

# Training hyperparameters
EPOCHS = 100
BATCH_SIZE = 1024
LR_INIT = 1e-5

# Class imbalance handling
POS_WEIGHT = 40
POS_WEIGHT_MODE = "fixed"  # "fixed" or "epoch"

# Dynamic negative sampling
USE_DYNAMIC_NEG_SAMPLING = False
NEG_SAMPLING_MODE = "ratio"  # "ratio" or "per_pos"
NEG_SAMPLE_RATIO = 0.20
```

### Data Annotation Format

Training data is annotated using Excel files:
- **Row 1**: FPS value (e.g., 24.0)
- **Subsequent rows**: One row per video, columns contain cut point timecodes

Timecode formats supported:
- Frame number: `51`
- Seconds:Frames: `02:14` (2 seconds, 14 frames)
- Hours:Minutes:Seconds: `01:23:45`

---

## ğŸ“Š Evaluation Metrics

The system provides comprehensive evaluation metrics:

| Metric | Description |
|--------|-------------|
| **Precision** | True positives / Predicted positives |
| **Recall** | True positives / Actual positives |
| **F1-Score** | Harmonic mean of Precision and Recall |
| **Accuracy** | Overall correct predictions |
| **PR-AUC (AP)** | Area under Precision-Recall curve |
| **ROC-AUC** | Area under ROC curve |
| **TP/FP/TN/FN** | Confusion matrix components |

### Per-Video Analysis

The evaluation includes per-video breakdown:
- Ground truth cut indices
- Predicted cut indices
- TP/FP/FN counts per video
- Top-K suspect frames (for FP/FN analysis)

---

## ğŸ› ï¸ Tools

### Dataset Tool

A Flask-based web application for dataset creation:
- Extract frames from videos
- Parse XML annotation files
- Generate cut/non-cut frame pairs
- Support for multiple video formats (MP4, MOV, AVI, MKV)

### Movie Cut

A Streamlit application for video frame sampling:
- Load videos from directory
- Configure sampling interval
- Save frames as PNG images
- Progress tracking

### Reports System

A Flask-based web application for viewing training reports:
- Parse training metrics from Excel files
- Display precision, recall, F1, AUC curves
- Show per-video test results
- Environment information display

---

## ğŸ“‹ Model Comparison

| Model | Input | Parameters | Use Case |
|-------|-------|------------|----------|
| **CNN** | 9CH / 21CH | ~1.5M | Best accuracy, recommended |
| **MLP** | 9CH / 21CH | ~800K | Faster training, moderate accuracy |
| **Linear** | 9CH / 21CH | ~400K | Baseline, fastest |

---

## ğŸ”¬ Technical Details

### Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| PyTorch | 2.0+ | Deep learning framework |
| OpenCV | 4.10+ | Video/image processing |
| NumPy | 1.24+ | Numerical operations |
| openpyxl | 3.1+ | Excel file handling |
| Flask | 3.1+ | Web applications |
| Streamlit | 1.53+ | Interactive UI |

### Hardware Requirements

- **Minimum**: 8GB RAM, CPU-only (slow training)
- **Recommended**: 16GB RAM, NVIDIA GPU with 8GB+ VRAM
- **Tested on**: NVIDIA RTX 3090, NVIDIA A100

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“§ Contact

**Cyber-Yichen** - [@Cyber-Yichen](https://github.com/Cyber-Yichen)

Project Link: [https://github.com/Cyber-Yichen/CNN-Shot-Boundary-Detection](https://github.com/Cyber-Yichen/CNN-Shot-Boundary-Detection)

---

<p align="center">
  Made with â¤ï¸ for Computational Film Analysis
</p>
