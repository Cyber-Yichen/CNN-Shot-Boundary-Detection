{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa85581-076c-4fc9-8d7b-85cec1facbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import openpyxl\n",
    "\n",
    "# ---------- 数据版本 / 路径 ----------\n",
    "DATA_VERSION = \"v13\"\n",
    "PROJECT_ROOT = \"movie\"\n",
    "\n",
    "TRAIN_VIDEO_DIR  = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut\"\n",
    "TRAIN_EXCEL_FILE = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut.xlsx\"\n",
    "\n",
    "TEST_VIDEO_DIR   = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut_test\"\n",
    "TEST_EXCEL_FILE  = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut_test.xlsx\"\n",
    "\n",
    "REPORTS_BASE_DIR = f\"{PROJECT_ROOT}/reports\"\n",
    "\n",
    "# ---------- 输入尺寸 ----------\n",
    "FRAME_SIZE = (224, 224)  # (H,W)\n",
    "\n",
    "# ---------- 训练超参数 ----------\n",
    "EPOCHS     = 100\n",
    "BATCH_SIZE = 1024\n",
    "LR_INIT    = 1e-5\n",
    "\n",
    "# ---------- 类不平衡（pos_weight） ----------\n",
    "POS_WEIGHT           = 40\n",
    "POS_WEIGHT_MODE      = \"fixed\"   # \"fixed\" / \"epoch\"\n",
    "POS_WEIGHT_EPOCH_MAX = 80.0\n",
    "\n",
    "# ---------- 负例抽样（每epoch动态抽负例） ----------\n",
    "USE_DYNAMIC_NEG_SAMPLING = False\n",
    "NEG_SAMPLING_MODE        = \"ratio\"    # \"ratio\" or \"per_pos\"\n",
    "NEG_SAMPLE_RATIO         = 0.20\n",
    "NEG_PER_POS              = 5\n",
    "\n",
    "SEED_SPLIT      = 42\n",
    "SEED_EPOCH_BASE = 20260118\n",
    "\n",
    "# ---------- CUDA/性能相关 ----------\n",
    "USE_CUDA          = True\n",
    "CUDA_DEVICE_INDEX = 0\n",
    "\n",
    "CUDNN_BENCHMARK     = True\n",
    "CUDNN_DETERMINISTIC = False\n",
    "\n",
    "ALLOW_TF32 = True\n",
    "MATMUL_PRECISION = \"high\"\n",
    "\n",
    "DATALOADER_NUM_WORKERS        = 12\n",
    "DATALOADER_PIN_MEMORY         = True\n",
    "DATALOADER_PERSISTENT_WORKERS = True\n",
    "\n",
    "# ---------- 向下兼容：旧变量名别名 ----------\n",
    "video_dir  = TRAIN_VIDEO_DIR\n",
    "excel_file = TRAIN_EXCEL_FILE\n",
    "frame_size = FRAME_SIZE\n",
    "\n",
    "# 数据读取\n",
    "\n",
    "wb = openpyxl.load_workbook(excel_file, data_only=True)\n",
    "ws = wb.active\n",
    "rows = list(ws.iter_rows(values_only=True))\n",
    "if len(rows) == 0:\n",
    "    raise RuntimeError(\"Excel 里没有任何行！\")\n",
    "\n",
    "fps_row = rows[0]\n",
    "\n",
    "def get_fps_from_row(r, default=24.0):\n",
    "    for cell in r:\n",
    "        if cell is None:\n",
    "            continue\n",
    "        if isinstance(cell, (int, float)):\n",
    "            return float(cell)\n",
    "        if isinstance(cell, str):\n",
    "            s = cell.strip()\n",
    "            if s == \"\" or s.lower() == \"none\":\n",
    "                continue\n",
    "            try:\n",
    "                return float(s)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return float(default)\n",
    "\n",
    "fps = get_fps_from_row(fps_row, default=24.0)\n",
    "print(f\"Using FPS from Excel first row: {fps}\")\n",
    "\n",
    "data_rows = rows[1:]\n",
    "\n",
    "video_files = sorted(glob.glob(f\"{video_dir}/V*.mp4\"))\n",
    "assert len(video_files) == len(data_rows), f\"Mismatch between number of videos ({len(video_files)}) and Excel data rows ({len(data_rows)})\"\n",
    "\n",
    "def timecode_to_frame(tc, fps):\n",
    "    if tc is None:\n",
    "        return None\n",
    "    if isinstance(tc, (int, float)):\n",
    "        return int(tc)\n",
    "\n",
    "    if isinstance(tc, str):\n",
    "        s = tc.strip()\n",
    "        if s == \"\" or s.lower() == \"none\":\n",
    "            return None\n",
    "        if s.isdigit():\n",
    "            return int(s)\n",
    "\n",
    "        if \":\" in s:\n",
    "            parts = s.split(\":\")\n",
    "            try:\n",
    "                if len(parts) == 2:\n",
    "                    sec = int(parts[0]); frm = int(parts[1])\n",
    "                    return int(sec * fps + frm)\n",
    "                elif len(parts) == 3:\n",
    "                    h = int(parts[0]); m = int(parts[1]); sec = int(parts[2])\n",
    "                    total_sec = h * 3600 + m * 60 + sec\n",
    "                    return int(total_sec * fps)\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "video_frames = []\n",
    "boundary_pairs = []\n",
    "boundary_pairs_by_video = []\n",
    "cut_indices_list = []\n",
    "total_frames_list = []\n",
    "valid_video_mask = []\n",
    "video_paths = list(video_files)\n",
    "\n",
    "for vid_idx, (video_path, row) in enumerate(zip(video_files, data_rows)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        frame_resized = cv2.resize(frame, frame_size)\n",
    "        frames.append(frame_resized)\n",
    "        success, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    video_frames.append(frames)\n",
    "    total_frames = len(frames)\n",
    "    total_frames_list.append(total_frames)\n",
    "\n",
    "    if total_frames <= 1:\n",
    "        valid_video_mask.append(False)\n",
    "        boundary_pairs_by_video.append([])\n",
    "        cut_indices_list.append([])\n",
    "        print(f\"Warning: video {video_path} has {total_frames} frame(s), skip boundary generation.\")\n",
    "        continue\n",
    "\n",
    "    valid_video_mask.append(True)\n",
    "\n",
    "    raw_values = list(row) if row is not None else []\n",
    "    cut_indices = []\n",
    "\n",
    "    for v in raw_values:\n",
    "        frame_idx = timecode_to_frame(v, fps)\n",
    "        if frame_idx is None:\n",
    "            continue\n",
    "\n",
    "        # Excel 标的是切后镜头起始帧(B-start)，SBD cut 应落在 (B-1,B) => i=B-1\n",
    "        if frame_idx > 0:\n",
    "            frame_idx -= 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        frame_idx = max(0, min(int(frame_idx), total_frames - 2))\n",
    "        cut_indices.append(frame_idx)\n",
    "\n",
    "    cut_indices = sorted(set(cut_indices))\n",
    "    cut_indices_list.append(cut_indices)\n",
    "\n",
    "    print(f\"Video {vid_idx} ({video_path}): total_frames={total_frames}, cuts-1@frames={cut_indices}\")\n",
    "\n",
    "    cut_set = set(cut_indices)\n",
    "\n",
    "    per_video_pairs = []\n",
    "    for i in range(total_frames - 1):\n",
    "        label = 1 if i in cut_set else 0\n",
    "        tup = (vid_idx, i, label)\n",
    "        boundary_pairs.append(tup)\n",
    "        per_video_pairs.append(tup)\n",
    "\n",
    "    boundary_pairs_by_video.append(per_video_pairs)\n",
    "\n",
    "num_videos = len(video_files)\n",
    "\n",
    "num_pairs = len(boundary_pairs)\n",
    "num_cuts = sum(1 for _, _, lbl in boundary_pairs if lbl == 1)\n",
    "num_noncuts = num_pairs - num_cuts\n",
    "\n",
    "total_extracted_frames = sum(len(frames) for frames in video_frames)\n",
    "num_valid_videos = sum(1 for v in valid_video_mask if v)\n",
    "\n",
    "print(f\"\\nProcessed {num_videos} videos (valid {num_valid_videos}/{num_videos}), extracted {total_extracted_frames} frames.\")\n",
    "print(f\"Generated {num_pairs} frame pairs: {num_cuts} cuts (positive) and {num_noncuts} non-cuts (negative).\")\n",
    "\n",
    "pos_count = num_cuts\n",
    "neg_count = num_noncuts\n",
    "pos_ratio = (pos_count / num_pairs) if num_pairs > 0 else 0.0\n",
    "neg_ratio = (neg_count / num_pairs) if num_pairs > 0 else 0.0\n",
    "print(f\"Pos ratio: {pos_ratio:.6f} | Neg ratio: {neg_ratio:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8327c6-d711-4b4e-9a4d-3e8beab50e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ShotBoundaryDataset(Dataset):\n",
    "    def __init__(self, pairs, video_frames):\n",
    "        self.pairs = pairs\n",
    "        self.video_frames = video_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_idx, frame_idx, label = self.pairs[idx]\n",
    "        frameA = self.video_frames[vid_idx][frame_idx]\n",
    "        frameB = self.video_frames[vid_idx][frame_idx + 1]\n",
    "\n",
    "        diff = cv2.absdiff(frameA, frameB)\n",
    "        img_9ch = np.concatenate([frameA, frameB, diff], axis=2).astype(\"float32\") / 255.0\n",
    "        img_9ch_chw = np.transpose(img_9ch, (2, 0, 1))\n",
    "\n",
    "        img_tensor = torch.tensor(img_9ch_chw, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "# ============= 划分训练测试 =============\n",
    "all_video_indices = list(range(num_videos))\n",
    "random.seed(SEED_SPLIT)\n",
    "random.shuffle(all_video_indices)\n",
    "\n",
    "split_idx = int(len(all_video_indices) * 0.95)\n",
    "train_vids = set(all_video_indices[:split_idx])\n",
    "test_vids  = set(all_video_indices[split_idx:])\n",
    "\n",
    "train_pairs_all = [p for p in boundary_pairs if p[0] in train_vids]\n",
    "test_pairs      = [p for p in boundary_pairs if p[0] in test_vids]\n",
    "\n",
    "train_pos_pairs = [p for p in train_pairs_all if p[2] == 1]\n",
    "train_neg_pairs = [p for p in train_pairs_all if p[2] == 0]\n",
    "\n",
    "# 测试集永远全量\n",
    "test_dataset = ShotBoundaryDataset(test_pairs, video_frames)\n",
    "\n",
    "_nw = int(globals().get(\"DATALOADER_NUM_WORKERS\", 0))\n",
    "_pw = bool(globals().get(\"DATALOADER_PERSISTENT_WORKERS\", False)) and (_nw > 0)\n",
    "\n",
    "test_loader  = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=_nw,\n",
    "    pin_memory=bool(globals().get(\"DATALOADER_PIN_MEMORY\", False)),\n",
    "    persistent_workers=_pw,\n",
    ")\n",
    "\n",
    "print(f\"[Split] train_vids={len(train_vids)} test_vids={len(test_vids)}\")\n",
    "print(f\"[Pool] train_pos={len(train_pos_pairs)} train_neg={len(train_neg_pairs)} test_total={len(test_pairs)}\")\n",
    "\n",
    "def make_train_loader_for_epoch(epoch: int, batch_size: int = BATCH_SIZE, shuffle: bool = True):\n",
    "    \"\"\"\n",
    "    每个epoch动态构造训练集：\n",
    "    - 正例：全量保留\n",
    "    - 负例：每轮重新随机抽样（可关）\n",
    "    \"\"\"\n",
    "    if (not USE_DYNAMIC_NEG_SAMPLING) or (len(train_neg_pairs) == 0):\n",
    "        epoch_pairs = list(train_pairs_all)\n",
    "        rng = None\n",
    "        raw_pos_weight_epoch = (len(train_neg_pairs) / max(1, len(train_pos_pairs))) if len(train_pos_pairs) > 0 else 1.0\n",
    "    else:\n",
    "        rng = random.Random(SEED_EPOCH_BASE + int(epoch))\n",
    "\n",
    "        if NEG_SAMPLING_MODE == \"ratio\":\n",
    "            k = int(len(train_neg_pairs) * float(NEG_SAMPLE_RATIO))\n",
    "        elif NEG_SAMPLING_MODE == \"per_pos\":\n",
    "            k = int(len(train_pos_pairs) * int(NEG_PER_POS))\n",
    "        else:\n",
    "            raise ValueError(\"NEG_SAMPLING_MODE must be 'ratio' or 'per_pos'\")\n",
    "\n",
    "        k = max(1, min(k, len(train_neg_pairs)))\n",
    "        neg_sample = rng.sample(train_neg_pairs, k)\n",
    "\n",
    "        epoch_pairs = list(train_pos_pairs) + neg_sample\n",
    "        rng.shuffle(epoch_pairs)\n",
    "\n",
    "        pos_n = len(train_pos_pairs)\n",
    "        neg_n = len(epoch_pairs) - pos_n\n",
    "        raw_pos_weight_epoch = (neg_n / max(1, pos_n))\n",
    "\n",
    "    train_dataset_epoch = ShotBoundaryDataset(epoch_pairs, video_frames)\n",
    "\n",
    "    _nw = int(globals().get(\"DATALOADER_NUM_WORKERS\", 0))\n",
    "    _pw = bool(globals().get(\"DATALOADER_PERSISTENT_WORKERS\", False)) and (_nw > 0)\n",
    "\n",
    "    train_loader_epoch  = DataLoader(\n",
    "        train_dataset_epoch,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=_nw,\n",
    "        pin_memory=bool(globals().get(\"DATALOADER_PIN_MEMORY\", False)),\n",
    "        persistent_workers=_pw,\n",
    "    )\n",
    "\n",
    "    pos_n = len(train_pos_pairs)\n",
    "    neg_n = len(train_dataset_epoch) - pos_n\n",
    "    print(f\"[Epoch {epoch}] train_pairs={len(train_dataset_epoch)} (pos {pos_n}, neg {neg_n}) raw_pos_weight_ep={raw_pos_weight_epoch:.4f}\")\n",
    "    return train_loader_epoch, train_dataset_epoch, raw_pos_weight_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2051640-cd8f-4f78-877b-3bb3b90a88f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============= Boundary CNN 训练部分 =============\n",
    "import os\n",
    "import platform\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    _TZ = ZoneInfo(\"Asia/BeiJing\")\n",
    "except Exception:\n",
    "    _TZ = None\n",
    "\n",
    "def _g(name, default=None):\n",
    "    return globals().get(name, default)\n",
    "\n",
    "def _none_str(x):\n",
    "    return \"none\" if x is None else str(x)\n",
    "\n",
    "def simple_classification_report(y_true, y_pred, target_names):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    n_classes = len(target_names)\n",
    "    lines = []\n",
    "    acc = (y_true == y_pred).sum() / len(y_true) if len(y_true) > 0 else 0.0\n",
    "\n",
    "    lines.append(\"precision    recall  f1-score   support\")\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        name = target_names[i]\n",
    "        true_i = (y_true == i)\n",
    "        pred_i = (y_pred == i)\n",
    "\n",
    "        tp = np.logical_and(true_i, pred_i).sum()\n",
    "        fp = np.logical_and(~true_i, pred_i).sum()\n",
    "        fn = np.logical_and(true_i, ~pred_i).sum()\n",
    "        support = true_i.sum()\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        lines.append(f\"{name:>9} {precision:9.4f} {recall:9.4f} {f1:9.4f} {support:9d}\")\n",
    "\n",
    "    lines.append(f\"\\naccuracy {acc:9.4f} {len(y_true):9d}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ===== 二分类指标 =====\n",
    "def binary_metrics_from_probs(y_true, prob_pos, threshold=0.5):\n",
    "    y_true = np.array(y_true).astype(int)\n",
    "    prob_pos = np.array(prob_pos).astype(float)\n",
    "    y_pred = (prob_pos >= threshold).astype(int)\n",
    "\n",
    "    tp = int(np.logical_and(y_true == 1, y_pred == 1).sum())\n",
    "    fp = int(np.logical_and(y_true == 0, y_pred == 1).sum())\n",
    "    tn = int(np.logical_and(y_true == 0, y_pred == 0).sum())\n",
    "    fn = int(np.logical_and(y_true == 1, y_pred == 0).sum())\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1        = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "    acc       = (tp + tn) / max(1, (tp + tn + fp + fn))\n",
    "\n",
    "    pos_pred_rate = (tp + fp) / max(1, len(y_true))\n",
    "    avg_prob_pos = float(prob_pos[y_true == 1].mean()) if (y_true == 1).any() else 0.0\n",
    "    avg_prob_neg = float(prob_pos[y_true == 0].mean()) if (y_true == 0).any() else 0.0\n",
    "\n",
    "    return {\n",
    "        \"threshold\": float(threshold),\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1\": float(f1),\n",
    "        \"acc\": float(acc),\n",
    "        \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn,\n",
    "        \"pos_pred_rate\": float(pos_pred_rate),\n",
    "        \"avg_prob_pos\": float(avg_prob_pos),\n",
    "        \"avg_prob_neg\": float(avg_prob_neg),\n",
    "    }\n",
    "\n",
    "# ===== 简单 AP / AUC =====\n",
    "def average_precision_score(y_true, prob_pos):\n",
    "    y_true = np.array(y_true).astype(int)\n",
    "    prob_pos = np.array(prob_pos).astype(float)\n",
    "    order = np.argsort(-prob_pos)\n",
    "    y = y_true[order]\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    P = max(1, int(y_true.sum()))\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        precisions.append(tp / max(1, (tp + fp)))\n",
    "        recalls.append(tp / P)\n",
    "    ap = 0.0\n",
    "    prev_r = 0.0\n",
    "    for p, r in zip(precisions, recalls):\n",
    "        ap += p * max(0.0, r - prev_r)\n",
    "        prev_r = r\n",
    "    return float(ap)\n",
    "\n",
    "def roc_auc_score_rank(y_true, prob_pos):\n",
    "    y_true = np.array(y_true).astype(int)\n",
    "    prob_pos = np.array(prob_pos).astype(float)\n",
    "    pos = prob_pos[y_true == 1]\n",
    "    neg = prob_pos[y_true == 0]\n",
    "    if len(pos) == 0 or len(neg) == 0:\n",
    "        return 0.0\n",
    "    # Mann–Whitney U\n",
    "    all_scores = np.concatenate([pos, neg])\n",
    "    ranks = all_scores.argsort().argsort() + 1\n",
    "    r_pos = ranks[:len(pos)]\n",
    "    U = r_pos.sum() - len(pos) * (len(pos) + 1) / 2\n",
    "    auc = U / (len(pos) * len(neg))\n",
    "    return float(auc)\n",
    "\n",
    "# ===== 设备 =====\n",
    "if bool(_g(\"USE_CUDA\", True)) and torch.cuda.is_available():\n",
    "    _cuda_idx = int(_g(\"CUDA_DEVICE_INDEX\", 0))\n",
    "    device = torch.device(f\"cuda:{_cuda_idx}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "try:\n",
    "    torch.backends.cudnn.benchmark = bool(_g(\"CUDNN_BENCHMARK\", True))\n",
    "    torch.backends.cudnn.deterministic = bool(_g(\"CUDNN_DETERMINISTIC\", False))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = bool(_g(\"ALLOW_TF32\", True))\n",
    "    torch.backends.cudnn.allow_tf32 = bool(_g(\"ALLOW_TF32\", True))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(str(_g(\"MATMUL_PRECISION\", \"high\")))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----- Model -----\n",
    "class BoundaryCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoundaryCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(9, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * (frame_size[0] // (2**3)) * (frame_size[1] // (2**3)), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "boundary_model = BoundaryCNN().to(device)\n",
    "\n",
    "pos_weight = float(_g(\"POS_WEIGHT\", 1.0))\n",
    "raw_pos_weight = None\n",
    "if num_cuts > 0:\n",
    "    raw_pos_weight = num_noncuts / max(1, num_cuts)\n",
    "\n",
    "print(f\"raw_pos_weight = {raw_pos_weight if raw_pos_weight is not None else 'NA'}, nominal pos_weight = {pos_weight}\")\n",
    "\n",
    "class_weights = torch.tensor([1.0, float(pos_weight)], dtype=torch.float32).to(device)\n",
    "criterion_b = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer_b = optim.Adam(boundary_model.parameters(), lr=float(_g(\"LR_INIT\", 1e-3)))\n",
    "\n",
    "# ===== 系统信息 =====\n",
    "def get_system_info():\n",
    "    info = {}\n",
    "    info[\"time_start\"] = datetime.now(_TZ).strftime(\"%Y-%m-%d %H:%M:%S %Z\") if _TZ else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    info[\"python_version\"] = platform.python_version()\n",
    "    info[\"platform\"] = platform.platform()\n",
    "    info[\"processor\"] = platform.processor()\n",
    "    info[\"torch_version\"] = torch.__version__\n",
    "    info[\"cuda_available\"] = str(torch.cuda.is_available())\n",
    "    info[\"device_used\"] = str(device)\n",
    "    try:\n",
    "        info[\"cuda_device_count\"] = str(torch.cuda.device_count()) if torch.cuda.is_available() else \"0\"\n",
    "        info[\"cuda_device_name_0\"] = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"NA\"\n",
    "    except Exception:\n",
    "        info[\"cuda_device_count\"] = \"NA\"\n",
    "        info[\"cuda_device_name_0\"] = \"NA\"\n",
    "    return info\n",
    "\n",
    "run_info = get_system_info()\n",
    "\n",
    "# ===== 训练 =====\n",
    "epochs = int(_g(\"EPOCHS\", 1))\n",
    "threshold_default = 0.95\n",
    "\n",
    "t0 = time.time()\n",
    "global_step = 0\n",
    "epoch_rows = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    boundary_model.train()\n",
    "\n",
    "    train_loader, train_dataset, raw_pos_weight_epoch = make_train_loader_for_epoch(epoch, batch_size=int(_g(\"BATCH_SIZE\", 32)), shuffle=True)\n",
    "\n",
    "    mode = str(_g(\"POS_WEIGHT_MODE\", \"fixed\")).lower()\n",
    "    if mode == \"fixed\":\n",
    "        used_pos_weight_epoch = float(pos_weight)\n",
    "    elif mode == \"epoch\":\n",
    "        used_pos_weight_epoch = float(min(float(raw_pos_weight_epoch), float(_g(\"POS_WEIGHT_EPOCH_MAX\", pos_weight))))\n",
    "    else:\n",
    "        used_pos_weight_epoch = float(pos_weight)  # 兜底\n",
    "\n",
    "    class_weights = torch.tensor([1.0, used_pos_weight_epoch], dtype=torch.float32).to(device)\n",
    "    criterion_b = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    losses = []\n",
    "    y_true_ep, prob_pos_ep = [], []\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_b.zero_grad()\n",
    "        outputs = boundary_model(imgs)\n",
    "        loss = criterion_b(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_b.step()\n",
    "\n",
    "        losses.append(float(loss.item()))\n",
    "        probs = torch.softmax(outputs.detach(), dim=1)[:, 1].detach().cpu().numpy().tolist()\n",
    "        y_true_ep.extend(labels.detach().cpu().numpy().tolist())\n",
    "        prob_pos_ep.extend(probs)\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    m = binary_metrics_from_probs(y_true_ep, prob_pos_ep, threshold=threshold_default)\n",
    "    ap = average_precision_score(y_true_ep, prob_pos_ep)\n",
    "    auc = roc_auc_score_rank(y_true_ep, prob_pos_ep)\n",
    "\n",
    "    lr_now = optimizer_b.param_groups[0].get(\"lr\", None)\n",
    "\n",
    "    print(\n",
    "        f\"[Boundary] Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"loss {np.mean(losses) if len(losses) else 0.0:.4f} | \"\n",
    "        f\"F1 {m['f1']:.4f} (P {m['precision']:.4f}, R {m['recall']:.4f}) | \"\n",
    "        f\"AP {ap:.4f} | AUC {auc:.4f} | \"\n",
    "        f\"TP {m['tp']} FP {m['fp']} TN {m['tn']} FN {m['fn']} | \"\n",
    "        f\"pos_pred_rate {m['pos_pred_rate']:.4f} | \"\n",
    "        f\"pos_weight {used_pos_weight_epoch:.2f} (raw_ep {raw_pos_weight_epoch:.2f})\"\n",
    "    )\n",
    "\n",
    "    epoch_rows.append({\n",
    "        \"epoch\": int(epoch+1),\n",
    "        \"global_step\": int(global_step),\n",
    "        \"loss\": float(np.mean(losses) if len(losses) else 0.0),\n",
    "        \"lr\": float(lr_now) if lr_now is not None else None,\n",
    "        \"threshold\": float(threshold_default),\n",
    "        \"precision\": float(m[\"precision\"]),\n",
    "        \"recall\": float(m[\"recall\"]),\n",
    "        \"f1\": float(m[\"f1\"]),\n",
    "        \"acc\": float(m[\"acc\"]),\n",
    "        \"tp\": int(m[\"tp\"]), \"fp\": int(m[\"fp\"]), \"tn\": int(m[\"tn\"]), \"fn\": int(m[\"fn\"]),\n",
    "        \"pos_pred_rate\": float(m[\"pos_pred_rate\"]),\n",
    "        \"avg_prob_pos\": float(m[\"avg_prob_pos\"]),\n",
    "        \"avg_prob_neg\": float(m[\"avg_prob_neg\"]),\n",
    "        \"pr_auc_ap\": float(ap),\n",
    "        \"roc_auc\": float(auc),\n",
    "        \"best_threshold_train\": None,\n",
    "        \"best_f1_train\": None,\n",
    "        \"raw_pos_weight\": float(raw_pos_weight) if raw_pos_weight is not None else None,\n",
    "        \"pos_weight\": float(pos_weight),  # 旧字段：固定“名义pos_weight”\n",
    "        \"weight_noncut\": float(class_weights[0].item()) if class_weights is not None else None,\n",
    "        \"weight_cut\": float(class_weights[1].item()) if class_weights is not None else None,\n",
    "        \"train_pairs_epoch\": int(len(train_loader.dataset)) if hasattr(train_loader, \"dataset\") else None,\n",
    "        \"raw_pos_weight_epoch\": float(raw_pos_weight_epoch) if raw_pos_weight_epoch is not None else None,\n",
    "        \"pos_weight_mode\": str(_g(\"POS_WEIGHT_MODE\", \"none\")),\n",
    "        \"pos_weight_used_epoch\": float(used_pos_weight_epoch) if used_pos_weight_epoch is not None else None,\n",
    "        \"neg_sampling_enabled\": bool(_g(\"USE_DYNAMIC_NEG_SAMPLING\", False)),\n",
    "        \"neg_sampling_mode\": str(_g(\"NEG_SAMPLING_MODE\", \"none\")),\n",
    "        \"neg_sample_ratio\": float(_g(\"NEG_SAMPLE_RATIO\", 0.0)) if _g(\"NEG_SAMPLE_RATIO\", None) is not None else None,\n",
    "        \"neg_per_pos\": int(_g(\"NEG_PER_POS\", 0)) if _g(\"NEG_PER_POS\", None) is not None else None,\n",
    "    })\n",
    "\n",
    "print(\"Finished training boundary detection model.\")\n",
    "t_train = time.time() - t0\n",
    "\n",
    "boundary_model.eval()\n",
    "y_true_b, prob_pos_b, y_pred_b = [], [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = boundary_model(imgs)\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        pred = (probs >= threshold_default).long()\n",
    "\n",
    "        y_true_b.extend(labels.detach().cpu().numpy().tolist())\n",
    "        prob_pos_b.extend(probs.detach().cpu().numpy().tolist())\n",
    "        y_pred_b.extend(pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "m_test = binary_metrics_from_probs(y_true_b, prob_pos_b, threshold=threshold_default)\n",
    "ap_test = average_precision_score(y_true_b, prob_pos_b)\n",
    "auc_test = roc_auc_score_rank(y_true_b, prob_pos_b)\n",
    "\n",
    "print(\"\\n[Boundary] FINAL TEST (threshold=0.95) => \"\n",
    "      f\"F1 {m_test['f1']:.4f} (P {m_test['precision']:.4f}, R {m_test['recall']:.4f}) | \"\n",
    "      f\"AP {ap_test:.4f} | AUC {auc_test:.4f} | \"\n",
    "      f\"TP {m_test['tp']} FP {m_test['fp']} TN {m_test['tn']} FN {m_test['fn']}\")\n",
    "\n",
    "print(\"\\nShot Boundary Detection - Classification Report (TEST):\")\n",
    "print(simple_classification_report(y_true_b, y_pred_b, target_names=[\"Non-cut\", \"Cut\"]))\n",
    "\n",
    "# ===== 写 Excel（保持原 sheet/列结构）=====\n",
    "base_dir = str(_g(\"REPORTS_BASE_DIR\", \"movie/reports\"))\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "ts_folder = datetime.now(_TZ).strftime(\"%m%d%H%M\") if _TZ else datetime.now().strftime(\"%m%d%H%M\")\n",
    "REPORT_FOLDER_NAME = f\"{ts_folder}_e{epochs}_w{int(pos_weight)}_{_none_str(_g('DATA_VERSION', 'NA'))}\"\n",
    "REPORT_DIR = os.path.join(base_dir, REPORT_FOLDER_NAME)\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "ts = datetime.now(_TZ).strftime(\"%Y%m%d_%H%M%S\") if _TZ else datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(REPORT_DIR, f\"boundary_train_metrics_{ts}.xlsx\")\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "\n",
    "# Sheet 1: run_info\n",
    "ws0 = wb.active\n",
    "ws0.title = \"run_info\"\n",
    "ws0.append([\"key\", \"value\"])\n",
    "for k, v in run_info.items():\n",
    "    ws0.append([k, str(v)])\n",
    "\n",
    "ws0.append([\"\"])\n",
    "ws0.append([\"epochs\", _none_str(epochs)])\n",
    "ws0.append([\"train_seconds\", f\"{t_train:.3f}\"])\n",
    "ws0.append([\"threshold_default\", _none_str(threshold_default)])\n",
    "ws0.append([\"optimizer\", \"Adam\"])\n",
    "ws0.append([\"lr_init\", _none_str(_g(\"LR_INIT\", None))])\n",
    "ws0.append([\"loss\", \"CrossEntropyLoss(weighted)\"])\n",
    "ws0.append([\"class_weight_noncut\", _none_str(1.0)])\n",
    "ws0.append([\"class_weight_cut\", _none_str(pos_weight)])\n",
    "ws0.append([\"raw_pos_weight\", _none_str(raw_pos_weight)])\n",
    "ws0.append([\"pos_weight_used\", _none_str(pos_weight)])\n",
    "ws0.append([\"\"])\n",
    "ws0.append([\"pos_weight_mode\", _none_str(_g(\"POS_WEIGHT_MODE\", None))])\n",
    "ws0.append([\"pos_weight_epoch_max\", _none_str(_g(\"POS_WEIGHT_EPOCH_MAX\", None))])\n",
    "ws0.append([\"neg_sampling_enabled\", _none_str(_g(\"USE_DYNAMIC_NEG_SAMPLING\", None))])\n",
    "ws0.append([\"neg_sampling_mode\", _none_str(_g(\"NEG_SAMPLING_MODE\", None))])\n",
    "ws0.append([\"neg_sample_ratio\", _none_str(_g(\"NEG_SAMPLE_RATIO\", None))])\n",
    "ws0.append([\"neg_per_pos\", _none_str(_g(\"NEG_PER_POS\", None))])\n",
    "ws0.append([\"\"])\n",
    "ws0.append([\"report_folder_name\", REPORT_FOLDER_NAME])\n",
    "ws0.append([\"report_dir\", REPORT_DIR])\n",
    "\n",
    "\n",
    "ws1 = wb.create_sheet(\"epoch_metrics\")\n",
    "cols = [\n",
    "    \"epoch\",\"global_step\",\"loss\",\"lr\",\n",
    "    \"threshold\",\"precision\",\"recall\",\"f1\",\"acc\",\n",
    "    \"tp\",\"fp\",\"tn\",\"fn\",\n",
    "    \"pos_pred_rate\",\"avg_prob_pos\",\"avg_prob_neg\",\n",
    "    \"pr_auc_ap\",\"roc_auc\",\n",
    "    \"best_threshold_train\",\"best_f1_train\",\n",
    "    \"raw_pos_weight\",\"pos_weight\",\"weight_noncut\",\"weight_cut\"\n",
    "]\n",
    "extra_cols = [\n",
    "    \"train_pairs_epoch\",\n",
    "    \"raw_pos_weight_epoch\",\n",
    "    \"pos_weight_mode\",\n",
    "    \"pos_weight_used_epoch\",\n",
    "    \"neg_sampling_enabled\",\n",
    "    \"neg_sampling_mode\",\n",
    "    \"neg_sample_ratio\",\n",
    "    \"neg_per_pos\"\n",
    "]\n",
    "all_cols = cols + extra_cols\n",
    "\n",
    "ws1.append(all_cols)\n",
    "for r in epoch_rows:\n",
    "    ws1.append([r.get(c, None) for c in all_cols])\n",
    "\n",
    "ws2 = wb.create_sheet(\"final_test\")\n",
    "ws2.append([\"metric\", \"value\"])\n",
    "ws2.append([\"threshold\", m_test[\"threshold\"]])\n",
    "ws2.append([\"precision\", m_test[\"precision\"]])\n",
    "ws2.append([\"recall\", m_test[\"recall\"]])\n",
    "ws2.append([\"f1\", m_test[\"f1\"]])\n",
    "ws2.append([\"acc\", m_test[\"acc\"]])\n",
    "ws2.append([\"tp\", m_test[\"tp\"]])\n",
    "ws2.append([\"fp\", m_test[\"fp\"]])\n",
    "ws2.append([\"tn\", m_test[\"tn\"]])\n",
    "ws2.append([\"fn\", m_test[\"fn\"]])\n",
    "ws2.append([\"pos_pred_rate\", m_test[\"pos_pred_rate\"]])\n",
    "ws2.append([\"avg_prob_pos\", m_test[\"avg_prob_pos\"]])\n",
    "ws2.append([\"avg_prob_neg\", m_test[\"avg_prob_neg\"]])\n",
    "ws2.append([\"pr_auc_ap\", ap_test])\n",
    "ws2.append([\"roc_auc\", auc_test])\n",
    "\n",
    "ws2.append([\"\"])\n",
    "ws2.append([\"classification_report\", \"\"])\n",
    "report_str = simple_classification_report(y_true_b, y_pred_b, target_names=[\"Non-cut\", \"Cut\"])\n",
    "for line in report_str.splitlines():\n",
    "    ws2.append([line, \"\"])\n",
    "\n",
    "wb.save(out_path)\n",
    "print(f\"\\nSaved metrics Excel to: {out_path}\")\n",
    "print(f\"[Report] Folder: {REPORT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e38e9-a909-41b7-9b63-7018f41498d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import platform\n",
    "\n",
    "def _g(name, default=None):\n",
    "    return globals().get(name, default)\n",
    "\n",
    "if \"boundary_model\" not in globals() or boundary_model is None:\n",
    "    raise RuntimeError(\"boundary_model 不存在：请先运行 Cell3 完成训练/加载模型，再运行 Cell4。\")\n",
    "\n",
    "pos_weight = float(_g(\"pos_weight\", _g(\"POS_WEIGHT\", 1.0)))\n",
    "epochs = _g(\"epochs\", _g(\"EPOCHS\", None))\n",
    "\n",
    "\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo  # py>=3.9\n",
    "    _TZ = ZoneInfo(\"Asia/BeiJing\")\n",
    "except Exception:\n",
    "    _TZ = None\n",
    "\n",
    "test_video_dir  = globals().get(\"TEST_VIDEO_DIR\", f\"movie/{DATA_VERSION}/dataset/cut_test\")\n",
    "\n",
    "test_excel_file = globals().get(\"TEST_EXCEL_FILE\", f\"movie/{DATA_VERSION}/dataset/cut_test.xlsx\")\n",
    "\n",
    "\n",
    "threshold_default = 0.95\n",
    "batch_size = 1024\n",
    "topk_suspects = 10  \n",
    "\n",
    "if bool(globals().get(\"USE_CUDA\", True)) and torch.cuda.is_available():\n",
    "    _cuda_idx = int(globals().get(\"CUDA_DEVICE_INDEX\", 0))\n",
    "    device = torch.device(f\"cuda:{_cuda_idx}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "boundary_model.eval()\n",
    "\n",
    "wb = openpyxl.load_workbook(test_excel_file, data_only=True)\n",
    "ws = wb.active\n",
    "rows = list(ws.iter_rows(values_only=True))\n",
    "if len(rows) == 0:\n",
    "    raise RuntimeError(\"cut_test.xlsx 里没有任何行！\")\n",
    "\n",
    "fps_row = rows[0]\n",
    "\n",
    "def get_fps_from_row(r, default=24.0):\n",
    "    for cell in r:\n",
    "        if cell is None:\n",
    "            continue\n",
    "        if isinstance(cell, (int, float)):\n",
    "            return float(cell)\n",
    "        if isinstance(cell, str):\n",
    "            s = cell.strip()\n",
    "            if s == \"\" or s.lower() == \"none\":\n",
    "                continue\n",
    "            try:\n",
    "                return float(s)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return float(default)\n",
    "\n",
    "fps = get_fps_from_row(fps_row, default=24.0)\n",
    "print(f\"[cut_test] Using FPS from Excel first row: {fps}\")\n",
    "\n",
    "data_rows = rows[1:]\n",
    "video_files = sorted(glob.glob(f\"{test_video_dir}/V*.mp4\"))\n",
    "assert len(video_files) == len(data_rows), \\\n",
    "    f\"Mismatch: videos({len(video_files)}) vs excel rows({len(data_rows)})\"\n",
    "\n",
    "def timecode_to_frame(tc, fps):\n",
    "    if tc is None:\n",
    "        return None\n",
    "    if isinstance(tc, (int, float)):\n",
    "        return int(tc)\n",
    "    if isinstance(tc, str):\n",
    "        s = tc.strip()\n",
    "        if s == \"\" or s.lower() == \"none\":\n",
    "            return None\n",
    "        if s.isdigit():\n",
    "            return int(s)\n",
    "        if \":\" in s:\n",
    "            parts = s.split(\":\")\n",
    "            try:\n",
    "                if len(parts) == 2:\n",
    "                    # ss:ff 例如 \"01:12\" -> 1秒12帧 -> 1*fps+12\n",
    "                    sec = int(parts[0])\n",
    "                    frm = int(parts[1])\n",
    "                    return int(sec * fps + frm)\n",
    "                elif len(parts) == 3:\n",
    "                    # hh:mm:ss\n",
    "                    h = int(parts[0]); m = int(parts[1]); sec = int(parts[2])\n",
    "                    total_sec = h * 3600 + m * 60 + sec\n",
    "                    return int(total_sec * fps)\n",
    "                else:\n",
    "                    return None\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "video_frames = []\n",
    "boundary_pairs_test = []\n",
    "\n",
    "video_meta = []  # 每个视频：dict(total_frames, gt_cut_indices, name, path)\n",
    "\n",
    "for vid_idx, (video_path, row) in enumerate(zip(video_files, data_rows)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        frame_resized = cv2.resize(frame, frame_size)\n",
    "        frames.append(frame_resized)\n",
    "        success, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    video_frames.append(frames)\n",
    "    total_frames = len(frames)\n",
    "    if total_frames <= 1:\n",
    "        print(f\"[cut_test] Warning: {video_path} has {total_frames} frame(s), skip.\")\n",
    "        video_meta.append({\n",
    "            \"vid_idx\": vid_idx,\n",
    "            \"name\": os.path.basename(video_path),\n",
    "            \"path\": video_path,\n",
    "            \"total_frames\": total_frames,\n",
    "            \"gt_cut_indices\": [],\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    raw_values = list(row) if row is not None else []\n",
    "\n",
    "    cut_indices = []\n",
    "    for v in raw_values:\n",
    "        frame_idx = timecode_to_frame(v, fps)\n",
    "        if frame_idx is None:\n",
    "            continue\n",
    "\n",
    "        if frame_idx > 0:\n",
    "            frame_idx = frame_idx - 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        frame_idx = int(frame_idx)\n",
    "        frame_idx = max(0, min(frame_idx, total_frames - 2))\n",
    "        cut_indices.append(frame_idx)\n",
    "\n",
    "    cut_indices = sorted(set(cut_indices))\n",
    "    print(f\"[cut_test] Video {vid_idx} ({os.path.basename(video_path)}): total_frames={total_frames}, cuts-1@frames={cut_indices}\")\n",
    "\n",
    "    video_meta.append({\n",
    "        \"vid_idx\": vid_idx,\n",
    "        \"name\": os.path.basename(video_path),\n",
    "        \"path\": video_path,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"gt_cut_indices\": cut_indices,\n",
    "    })\n",
    "\n",
    "    cut_set = set(cut_indices)\n",
    "    for i in range(total_frames - 1):\n",
    "        label = 1 if i in cut_set else 0\n",
    "        boundary_pairs_test.append((vid_idx, i, label))\n",
    "\n",
    "num_pairs = len(boundary_pairs_test)\n",
    "num_cuts = sum(1 for _, _, lbl in boundary_pairs_test if lbl == 1)\n",
    "num_noncuts = num_pairs - num_cuts\n",
    "print(f\"\\n[cut_test] Generated {num_pairs} pairs: {num_cuts} cuts, {num_noncuts} non-cuts\")\n",
    "\n",
    "class ShotBoundaryDataset(Dataset):\n",
    "    def __init__(self, pairs, video_frames):\n",
    "        self.pairs = pairs\n",
    "        self.video_frames = video_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_idx, frame_idx, label = self.pairs[idx]\n",
    "        frameA = self.video_frames[vid_idx][frame_idx]\n",
    "        frameB = self.video_frames[vid_idx][frame_idx + 1]\n",
    "        diff = cv2.absdiff(frameA, frameB)\n",
    "\n",
    "        img_9ch = np.concatenate([frameA, frameB, diff], axis=2).astype(\"float32\") / 255.0\n",
    "        img_9ch_chw = np.transpose(img_9ch, (2, 0, 1))\n",
    "\n",
    "        img_tensor = torch.tensor(img_9ch_chw, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "test_dataset = ShotBoundaryDataset(boundary_pairs_test, video_frames)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "y_true, prob_pos, y_pred = [], [], []\n",
    "\n",
    "pair_details = []  # list of tuples\n",
    "\n",
    "pair_ptr = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        bsz = labels.size(0)\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = boundary_model(imgs)                 # logits [B,2]\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]    # P(cut)\n",
    "        pred = (probs >= threshold_default).long()\n",
    "\n",
    "        probs_np = probs.detach().cpu().numpy()\n",
    "        pred_np  = pred.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        y_true.extend(labels_np.tolist())\n",
    "        prob_pos.extend(probs_np.tolist())\n",
    "        y_pred.extend(pred_np.tolist())\n",
    "\n",
    "        for j in range(bsz):\n",
    "            vid_idx, frame_idx, gt = boundary_pairs_test[pair_ptr + j]\n",
    "            pair_details.append((vid_idx, frame_idx, int(gt), float(probs_np[j]), int(pred_np[j])))\n",
    "        pair_ptr += bsz\n",
    "\n",
    "m = binary_metrics_from_probs(y_true, prob_pos, threshold=threshold_default)\n",
    "ap = average_precision_score(y_true, prob_pos)\n",
    "auc = roc_auc_score_rank(y_true, prob_pos)\n",
    "\n",
    "print(\"\\n[cut_test] FINAL TEST (threshold=0.95) => \"\n",
    "      f\"F1 {m['f1']:.4f} (P {m['precision']:.4f}, R {m['recall']:.4f}) | \"\n",
    "      f\"AP {ap:.4f} | AUC {auc:.4f} | \"\n",
    "      f\"TP {m['tp']} FP {m['fp']} TN {m['tn']} FN {m['fn']}\")\n",
    "\n",
    "print(\"\\nShot Boundary Detection - Classification Report (cut_test):\")\n",
    "report_str = simple_classification_report(y_true, y_pred, target_names=[\"Non-cut\", \"Cut\"])\n",
    "print(report_str)\n",
    "\n",
    "per_video_pairs = {vm[\"vid_idx\"]: [] for vm in video_meta}\n",
    "for (vid_idx, frame_idx, gt, p, pred) in pair_details:\n",
    "    per_video_pairs[vid_idx].append((frame_idx, gt, p, pred))\n",
    "\n",
    "per_video_rows = []\n",
    "per_video_suspects_rows = []  \n",
    "\n",
    "for vm in video_meta:\n",
    "    vid_idx = vm[\"vid_idx\"]\n",
    "    name = vm[\"name\"]\n",
    "    total_frames = vm[\"total_frames\"]\n",
    "    gt_cuts = set(vm[\"gt_cut_indices\"])\n",
    "\n",
    "    pairs = per_video_pairs.get(vid_idx, [])\n",
    "    if not pairs:\n",
    "        per_video_rows.append({\n",
    "            \"vid\": name, \"vid_idx\": vid_idx, \"total_frames\": total_frames,\n",
    "            \"gt_cut_count\": len(gt_cuts), \"pred_cut_count\": 0,\n",
    "            \"tp\": 0, \"fp\": 0, \"fn\": len(gt_cuts),\n",
    "            \"gt_cuts\": \",\".join(map(str, sorted(gt_cuts))) if gt_cuts else \"none\",\n",
    "            \"pred_cuts\": \"none\",\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    pred_cuts = sorted({fr for (fr, gt, p, pred) in pairs if pred == 1})\n",
    "    pred_cut_set = set(pred_cuts)\n",
    "\n",
    "    tp = len(gt_cuts & pred_cut_set)\n",
    "    fp = len(pred_cut_set - gt_cuts)\n",
    "    fn = len(gt_cuts - pred_cut_set)\n",
    "\n",
    "    per_video_rows.append({\n",
    "        \"vid\": name, \"vid_idx\": vid_idx, \"total_frames\": total_frames,\n",
    "        \"gt_cut_count\": len(gt_cuts), \"pred_cut_count\": len(pred_cut_set),\n",
    "        \"tp\": tp, \"fp\": fp, \"fn\": fn,\n",
    "        \"gt_cuts\": \",\".join(map(str, sorted(gt_cuts))) if gt_cuts else \"none\",\n",
    "        \"pred_cuts\": \",\".join(map(str, pred_cuts)) if pred_cuts else \"none\",\n",
    "    })\n",
    "\n",
    "    fps_list = [(fr, p) for (fr, gt, p, pred) in pairs if gt == 0 and pred == 1]\n",
    "    fns_list = [(fr, p) for (fr, gt, p, pred) in pairs if gt == 1 and pred == 0]\n",
    "\n",
    "    fps_list = sorted(fps_list, key=lambda x: -x[1])[:topk_suspects]\n",
    "    fns_list = sorted(fns_list, key=lambda x: x[1])[:topk_suspects]\n",
    "\n",
    "    for rank, (fr, p) in enumerate(fps_list, start=1):\n",
    "        per_video_suspects_rows.append([name, vid_idx, \"FP\", rank, fr, float(p)])\n",
    "    for rank, (fr, p) in enumerate(fns_list, start=1):\n",
    "        per_video_suspects_rows.append([name, vid_idx, \"FN\", rank, fr, float(p)])\n",
    "\n",
    "base_dir = globals().get('REPORTS_BASE_DIR', 'movie/reports')\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "if \"REPORT_DIR\" not in globals() or \"REPORT_FOLDER_NAME\" not in globals():\n",
    "    ts_folder = datetime.now(_TZ).strftime(\"%m%d%H%M\") if _TZ else datetime.now().strftime(\"%m%d%H%M\")\n",
    "    # epochs / pos_weight 在 Cell4 里不一定存在，所以优先复用已有；没有就用占位\n",
    "    _e = globals().get(\"epochs\", \"NA\")\n",
    "    _w = globals().get(\"pos_weight\", \"NA\")\n",
    "    REPORT_FOLDER_NAME = f\"{ts_folder}_e{_e}_w{_w}\"\n",
    "    REPORT_DIR = os.path.join(base_dir, REPORT_FOLDER_NAME)\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "ts = datetime.now(_TZ).strftime(\"%Y%m%d_%H%M%S\") if _TZ else datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(REPORT_DIR, f\"cut_test_report_{ts}.xlsx\")\n",
    "\n",
    "\n",
    "wb_out = openpyxl.Workbook()\n",
    "\n",
    "ws0 = wb_out.active\n",
    "ws0.title = \"run_info\"\n",
    "ws0.append([\"key\", \"value\"])\n",
    "ws0.append([\"time\", datetime.now(_TZ).strftime(\"%Y-%m-%d %H:%M:%S %Z\") if _TZ else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")])\n",
    "ws0.append([\"python_version\", platform.python_version()])\n",
    "ws0.append([\"platform\", platform.platform()])\n",
    "ws0.append([\"processor\", platform.processor()])\n",
    "ws0.append([\"torch_version\", torch.__version__])\n",
    "ws0.append([\"cuda_available\", str(torch.cuda.is_available())])\n",
    "ws0.append([\"device_used\", str(device)])\n",
    "ws0.append([\"test_video_dir\", test_video_dir])\n",
    "ws0.append([\"test_excel_file\", test_excel_file])\n",
    "ws0.append([\"fps_from_excel\", str(fps)])\n",
    "ws0.append([\"threshold_default\", str(threshold_default)])\n",
    "ws0.append([\"batch_size\", str(batch_size)])\n",
    "ws0.append([\"topk_suspects\", str(topk_suspects)])\n",
    "ws0.append([\"report_folder_name\", REPORT_FOLDER_NAME])\n",
    "ws0.append([\"report_dir\", REPORT_DIR])\n",
    "\n",
    "ws_sum = wb_out.create_sheet(\"dataset_summary\")\n",
    "ws_sum.append([\"item\", \"value\"])\n",
    "ws_sum.append([\"num_videos\", len(video_files)])\n",
    "ws_sum.append([\"num_pairs\", num_pairs])\n",
    "ws_sum.append([\"num_cuts\", num_cuts])\n",
    "ws_sum.append([\"num_non_cuts\", num_noncuts])\n",
    "ws_sum.append([\"pos_ratio\", (num_cuts / num_pairs) if num_pairs else 0.0])\n",
    "\n",
    "ws_sum.append([\"\"])\n",
    "ws_sum.append([\"per_video_frame_stats\", \"\"])\n",
    "frames_list = [vm[\"total_frames\"] for vm in video_meta if vm[\"total_frames\"] is not None]\n",
    "if frames_list:\n",
    "    ws_sum.append([\"min_frames\", int(np.min(frames_list))])\n",
    "    ws_sum.append([\"max_frames\", int(np.max(frames_list))])\n",
    "    ws_sum.append([\"mean_frames\", float(np.mean(frames_list))])\n",
    "    ws_sum.append([\"median_frames\", float(np.median(frames_list))])\n",
    "\n",
    "ws_v = wb_out.create_sheet(\"per_video\")\n",
    "ws_v.append([\n",
    "    \"vid\", \"vid_idx\", \"total_frames\",\n",
    "    \"gt_cut_count\", \"pred_cut_count\",\n",
    "    \"tp\", \"fp\", \"fn\",\n",
    "    \"gt_cuts\", \"pred_cuts\"\n",
    "])\n",
    "for r in per_video_rows:\n",
    "    ws_v.append([\n",
    "        r[\"vid\"], r[\"vid_idx\"], r[\"total_frames\"],\n",
    "        r[\"gt_cut_count\"], r[\"pred_cut_count\"],\n",
    "        r[\"tp\"], r[\"fp\"], r[\"fn\"],\n",
    "        r[\"gt_cuts\"], r[\"pred_cuts\"]\n",
    "    ])\n",
    "\n",
    "ws_sus = wb_out.create_sheet(\"suspects_topk\")\n",
    "ws_sus.append([\"vid\", \"vid_idx\", \"type\", \"rank\", \"frame_idx\", \"prob_cut\"])\n",
    "for row in per_video_suspects_rows:\n",
    "    ws_sus.append(row)\n",
    "\n",
    "ws2 = wb_out.create_sheet(\"final_test\")\n",
    "ws2.append([\"metric\", \"value\"])\n",
    "ws2.append([\"threshold\", m[\"threshold\"]])\n",
    "ws2.append([\"precision\", m[\"precision\"]])\n",
    "ws2.append([\"recall\", m[\"recall\"]])\n",
    "ws2.append([\"f1\", m[\"f1\"]])\n",
    "ws2.append([\"acc\", m[\"acc\"]])\n",
    "ws2.append([\"tp\", m[\"tp\"]])\n",
    "ws2.append([\"fp\", m[\"fp\"]])\n",
    "ws2.append([\"tn\", m[\"tn\"]])\n",
    "ws2.append([\"fn\", m[\"fn\"]])\n",
    "ws2.append([\"pos_pred_rate\", m[\"pos_pred_rate\"]])\n",
    "ws2.append([\"avg_prob_pos\", m[\"avg_prob_pos\"]])\n",
    "ws2.append([\"avg_prob_neg\", m[\"avg_prob_neg\"]])\n",
    "ws2.append([\"pr_auc_ap\", ap])\n",
    "ws2.append([\"roc_auc\", auc])\n",
    "\n",
    "ws_rep = wb_out.create_sheet(\"classification_report\")\n",
    "ws_rep.append([\"text\"])\n",
    "for line in report_str.splitlines():\n",
    "    ws_rep.append([line])\n",
    "\n",
    "wb_out.save(out_path)\n",
    "print(f\"\\nSaved cut_test report Excel to: {out_path}\")\n",
    "print(f\"[Report] Folder: {REPORT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6527c37-a24f-4d36-9a13-f0d072fb51b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "    ts_model = datetime.now(_TZ).strftime(\"%Y%m%d_%H%M%S\") if _TZ else datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    model_path = os.path.join(REPORT_DIR, f\"boundary_model_{ts_model}.pt\")\n",
    "    ckpt_path  = os.path.join(REPORT_DIR, f\"boundary_ckpt_{ts_model}.pth\")\n",
    "\n",
    "    torch.save(boundary_model.state_dict(), model_path)\n",
    "\n",
    "    ckpt = {\n",
    "        \"model_state_dict\": boundary_model.state_dict(),\n",
    "        \"device_saved\": str(device),\n",
    "        \"fps_from_excel\": float(fps),\n",
    "        \"threshold_default\": float(threshold_default),\n",
    "        \"batch_size\": int(batch_size),\n",
    "        \"frame_size\": tuple(frame_size) if \"frame_size\" in globals() else None,\n",
    "        \"report_dir\": REPORT_DIR,\n",
    "        \"report_folder_name\": REPORT_FOLDER_NAME,\n",
    "        \"epochs\": globals().get(\"epochs\", None),\n",
    "        \"pos_weight\": globals().get(\"pos_weight\", None),\n",
    "        \"build_id\": globals().get(\"BUILD_ID\", None),\n",
    "        \"saved_time\": datetime.now(_TZ).strftime(\"%Y-%m-%d %H:%M:%S %Z\") if _TZ else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    torch.save(ckpt, ckpt_path)\n",
    "\n",
    "    print(f\"[Model] Saved state_dict to: {model_path}\")\n",
    "    print(f\"[Model] Saved checkpoint to: {ckpt_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[Model] Save failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
