{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcd4a7a-e054-46e8-9b83-cfb2de1a4252",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e00a1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===== Path config (aligned with Untitled2) =====\n",
    "PROJECT_ROOT = \"movie\"\n",
    "DATA_VERSION = \"v13\"\n",
    "REPORTS_BASE_DIR = f\"{PROJECT_ROOT}/reports\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d566f06-a3fe-42b7-87a7-7d15aa1ce1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FPS from Excel first row: 24.0\n",
      "Video 0 (movie/v13/dataset/cut/V001.mp4): total_frames=72, cuts-1@frames=[25, 51]\n",
      "Video 1 (movie/v13/dataset/cut/V002.mp4): total_frames=106, cuts-1@frames=[42, 57, 76]\n",
      "Video 2 (movie/v13/dataset/cut/V003.mp4): total_frames=160, cuts-1@frames=[9, 25, 50, 60, 102]\n",
      "Video 3 (movie/v13/dataset/cut/V004.mp4): total_frames=205, cuts-1@frames=[35, 147]\n",
      "Video 4 (movie/v13/dataset/cut/V005.mp4): total_frames=405, cuts-1@frames=[56, 75, 100, 127, 185, 208, 339, 378]\n",
      "Video 5 (movie/v13/dataset/cut/V006.mp4): total_frames=405, cuts-1@frames=[68, 118, 165, 200, 251, 268, 289, 329]\n",
      "Video 6 (movie/v13/dataset/cut/V007.mp4): total_frames=227, cuts-1@frames=[18, 61, 72, 82, 93, 105, 123, 141, 149, 158, 171, 199]\n",
      "Video 7 (movie/v13/dataset/cut/V008.mp4): total_frames=200, cuts-1@frames=[22, 59, 101, 118, 126, 136, 156, 162]\n",
      "Video 8 (movie/v13/dataset/cut/V009.mp4): total_frames=310, cuts-1@frames=[173]\n",
      "Video 9 (movie/v13/dataset/cut/V010.mp4): total_frames=240, cuts-1@frames=[22, 58, 90, 120, 166, 216]\n",
      "Video 10 (movie/v13/dataset/cut/V011.mp4): total_frames=269, cuts-1@frames=[90, 133, 175, 236]\n",
      "Video 11 (movie/v13/dataset/cut/V012.mp4): total_frames=310, cuts-1@frames=[48, 86, 137, 176]\n",
      "Video 12 (movie/v13/dataset/cut/V013.mp4): total_frames=612, cuts-1@frames=[37, 100, 129, 171, 271, 333, 380, 452, 494, 531, 574]\n",
      "Video 13 (movie/v13/dataset/cut/V014.mp4): total_frames=612, cuts-1@frames=[64, 243, 309, 331, 404, 517]\n",
      "Video 14 (movie/v13/dataset/cut/V015.mp4): total_frames=612, cuts-1@frames=[22, 106, 158, 261, 378, 415, 465, 590]\n",
      "Video 15 (movie/v13/dataset/cut/V016.mp4): total_frames=426, cuts-1@frames=[30, 70, 130, 150, 199, 223, 251, 338, 390]\n",
      "Video 16 (movie/v13/dataset/cut/V017.mp4): total_frames=387, cuts-1@frames=[]\n",
      "Video 17 (movie/v13/dataset/cut/V018.mp4): total_frames=323, cuts-1@frames=[24, 45, 63, 91, 117, 147, 184, 206, 229, 259, 304]\n",
      "Video 18 (movie/v13/dataset/cut/V019.mp4): total_frames=323, cuts-1@frames=[19, 53, 78, 102, 133, 158, 182, 205, 306]\n",
      "Video 19 (movie/v13/dataset/cut/V020.mp4): total_frames=105, cuts-1@frames=[22, 44, 67, 88]\n",
      "Video 20 (movie/v13/dataset/cut/V021.mp4): total_frames=122, cuts-1@frames=[13, 34, 55, 76, 107]\n",
      "Video 21 (movie/v13/dataset/cut/V022.mp4): total_frames=402, cuts-1@frames=[26, 103, 176, 207, 274, 385]\n",
      "Video 22 (movie/v13/dataset/cut/V023.mp4): total_frames=632, cuts-1@frames=[29, 119, 204, 239, 327, 493, 599]\n",
      "Video 23 (movie/v13/dataset/cut/V024.mp4): total_frames=773, cuts-1@frames=[60, 108, 143, 326, 531, 580, 674]\n",
      "Video 24 (movie/v13/dataset/cut/V025.mp4): total_frames=203, cuts-1@frames=[94, 154]\n",
      "Video 25 (movie/v13/dataset/cut/V026.mp4): total_frames=43, cuts-1@frames=[26]\n",
      "Video 26 (movie/v13/dataset/cut/V027.mp4): total_frames=161, cuts-1@frames=[86, 131]\n",
      "Video 27 (movie/v13/dataset/cut/V028.mp4): total_frames=122, cuts-1@frames=[18, 35, 56, 72, 105]\n",
      "Video 28 (movie/v13/dataset/cut/V029.mp4): total_frames=700, cuts-1@frames=[46, 419, 457, 504, 600, 643]\n",
      "Video 29 (movie/v13/dataset/cut/V030.mp4): total_frames=334, cuts-1@frames=[20, 69, 134, 169, 238, 263]\n",
      "Video 30 (movie/v13/dataset/cut/V031.mp4): total_frames=24, cuts-1@frames=[]\n",
      "Video 31 (movie/v13/dataset/cut/V032.mp4): total_frames=24, cuts-1@frames=[]\n",
      "Video 32 (movie/v13/dataset/cut/V033.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 33 (movie/v13/dataset/cut/V034.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 34 (movie/v13/dataset/cut/V035.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 35 (movie/v13/dataset/cut/V036.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 36 (movie/v13/dataset/cut/V037.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 37 (movie/v13/dataset/cut/V038.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 38 (movie/v13/dataset/cut/V039.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 39 (movie/v13/dataset/cut/V040.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 40 (movie/v13/dataset/cut/V041.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 41 (movie/v13/dataset/cut/V042.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 42 (movie/v13/dataset/cut/V043.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 43 (movie/v13/dataset/cut/V044.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 44 (movie/v13/dataset/cut/V045.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 45 (movie/v13/dataset/cut/V046.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 46 (movie/v13/dataset/cut/V047.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 47 (movie/v13/dataset/cut/V048.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 48 (movie/v13/dataset/cut/V049.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 49 (movie/v13/dataset/cut/V050.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 50 (movie/v13/dataset/cut/V051.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 51 (movie/v13/dataset/cut/V052.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 52 (movie/v13/dataset/cut/V053.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 53 (movie/v13/dataset/cut/V054.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 54 (movie/v13/dataset/cut/V055.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 55 (movie/v13/dataset/cut/V056.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 56 (movie/v13/dataset/cut/V057.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 57 (movie/v13/dataset/cut/V058.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 58 (movie/v13/dataset/cut/V059.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 59 (movie/v13/dataset/cut/V060.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 60 (movie/v13/dataset/cut/V061.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 61 (movie/v13/dataset/cut/V062.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 62 (movie/v13/dataset/cut/V063.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 63 (movie/v13/dataset/cut/V064.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 64 (movie/v13/dataset/cut/V065.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 65 (movie/v13/dataset/cut/V066.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 66 (movie/v13/dataset/cut/V067.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 67 (movie/v13/dataset/cut/V068.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 68 (movie/v13/dataset/cut/V069.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 69 (movie/v13/dataset/cut/V070.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 70 (movie/v13/dataset/cut/V071.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 71 (movie/v13/dataset/cut/V072.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 72 (movie/v13/dataset/cut/V073.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 73 (movie/v13/dataset/cut/V074.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 74 (movie/v13/dataset/cut/V075.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 75 (movie/v13/dataset/cut/V076.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 76 (movie/v13/dataset/cut/V077.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 77 (movie/v13/dataset/cut/V078.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 78 (movie/v13/dataset/cut/V079.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 79 (movie/v13/dataset/cut/V080.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 80 (movie/v13/dataset/cut/V081.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 81 (movie/v13/dataset/cut/V082.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 82 (movie/v13/dataset/cut/V083.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 83 (movie/v13/dataset/cut/V084.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 84 (movie/v13/dataset/cut/V085.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 85 (movie/v13/dataset/cut/V086.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 86 (movie/v13/dataset/cut/V087.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 87 (movie/v13/dataset/cut/V088.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 88 (movie/v13/dataset/cut/V089.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 89 (movie/v13/dataset/cut/V090.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 90 (movie/v13/dataset/cut/V091.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 91 (movie/v13/dataset/cut/V092.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 92 (movie/v13/dataset/cut/V093.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 93 (movie/v13/dataset/cut/V094.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 94 (movie/v13/dataset/cut/V095.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 95 (movie/v13/dataset/cut/V096.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 96 (movie/v13/dataset/cut/V097.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 97 (movie/v13/dataset/cut/V098.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 98 (movie/v13/dataset/cut/V099.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 99 (movie/v13/dataset/cut/V100.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 100 (movie/v13/dataset/cut/V101.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 101 (movie/v13/dataset/cut/V102.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 102 (movie/v13/dataset/cut/V103.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 103 (movie/v13/dataset/cut/V104.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 104 (movie/v13/dataset/cut/V105.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 105 (movie/v13/dataset/cut/V106.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 106 (movie/v13/dataset/cut/V107.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 107 (movie/v13/dataset/cut/V108.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 108 (movie/v13/dataset/cut/V109.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 109 (movie/v13/dataset/cut/V110.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 110 (movie/v13/dataset/cut/V111.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 111 (movie/v13/dataset/cut/V112.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 112 (movie/v13/dataset/cut/V113.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 113 (movie/v13/dataset/cut/V114.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 114 (movie/v13/dataset/cut/V115.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 115 (movie/v13/dataset/cut/V116.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 116 (movie/v13/dataset/cut/V117.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 117 (movie/v13/dataset/cut/V118.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 118 (movie/v13/dataset/cut/V119.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 119 (movie/v13/dataset/cut/V120.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 120 (movie/v13/dataset/cut/V121.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 121 (movie/v13/dataset/cut/V122.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 122 (movie/v13/dataset/cut/V123.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 123 (movie/v13/dataset/cut/V124.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 124 (movie/v13/dataset/cut/V125.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 125 (movie/v13/dataset/cut/V126.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 126 (movie/v13/dataset/cut/V127.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 127 (movie/v13/dataset/cut/V128.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 128 (movie/v13/dataset/cut/V129.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 129 (movie/v13/dataset/cut/V130.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 130 (movie/v13/dataset/cut/V131.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 131 (movie/v13/dataset/cut/V132.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 132 (movie/v13/dataset/cut/V133.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 133 (movie/v13/dataset/cut/V134.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 134 (movie/v13/dataset/cut/V135.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 135 (movie/v13/dataset/cut/V136.mp4): total_frames=72, cuts-1@frames=[]\n",
      "Video 136 (movie/v13/dataset/cut/V137.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 137 (movie/v13/dataset/cut/V138.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 138 (movie/v13/dataset/cut/V139.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 139 (movie/v13/dataset/cut/V140.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 140 (movie/v13/dataset/cut/V141.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 141 (movie/v13/dataset/cut/V142.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 142 (movie/v13/dataset/cut/V143.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 143 (movie/v13/dataset/cut/V144.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 144 (movie/v13/dataset/cut/V145.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 145 (movie/v13/dataset/cut/V146.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 146 (movie/v13/dataset/cut/V147.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 147 (movie/v13/dataset/cut/V148.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 148 (movie/v13/dataset/cut/V149.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 149 (movie/v13/dataset/cut/V150.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 150 (movie/v13/dataset/cut/V151.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 151 (movie/v13/dataset/cut/V152.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 152 (movie/v13/dataset/cut/V153.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 153 (movie/v13/dataset/cut/V154.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 154 (movie/v13/dataset/cut/V155.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 155 (movie/v13/dataset/cut/V156.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 156 (movie/v13/dataset/cut/V157.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 157 (movie/v13/dataset/cut/V158.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 158 (movie/v13/dataset/cut/V159.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 159 (movie/v13/dataset/cut/V160.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 160 (movie/v13/dataset/cut/V161.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 161 (movie/v13/dataset/cut/V162.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 162 (movie/v13/dataset/cut/V163.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 163 (movie/v13/dataset/cut/V164.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 164 (movie/v13/dataset/cut/V165.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 165 (movie/v13/dataset/cut/V166.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 166 (movie/v13/dataset/cut/V167.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 167 (movie/v13/dataset/cut/V168.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 168 (movie/v13/dataset/cut/V169.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 169 (movie/v13/dataset/cut/V170.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 170 (movie/v13/dataset/cut/V171.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 171 (movie/v13/dataset/cut/V172.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 172 (movie/v13/dataset/cut/V173.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 173 (movie/v13/dataset/cut/V174.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 174 (movie/v13/dataset/cut/V175.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 175 (movie/v13/dataset/cut/V176.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 176 (movie/v13/dataset/cut/V177.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 177 (movie/v13/dataset/cut/V178.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 178 (movie/v13/dataset/cut/V179.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 179 (movie/v13/dataset/cut/V180.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 180 (movie/v13/dataset/cut/V181.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 181 (movie/v13/dataset/cut/V182.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 182 (movie/v13/dataset/cut/V183.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 183 (movie/v13/dataset/cut/V184.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 184 (movie/v13/dataset/cut/V185.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 185 (movie/v13/dataset/cut/V186.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 186 (movie/v13/dataset/cut/V187.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 187 (movie/v13/dataset/cut/V188.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 188 (movie/v13/dataset/cut/V189.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 189 (movie/v13/dataset/cut/V190.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 190 (movie/v13/dataset/cut/V191.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 191 (movie/v13/dataset/cut/V192.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 192 (movie/v13/dataset/cut/V193.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 193 (movie/v13/dataset/cut/V194.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 194 (movie/v13/dataset/cut/V195.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 195 (movie/v13/dataset/cut/V196.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 196 (movie/v13/dataset/cut/V197.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 197 (movie/v13/dataset/cut/V198.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 198 (movie/v13/dataset/cut/V199.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 199 (movie/v13/dataset/cut/V200.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 200 (movie/v13/dataset/cut/V201.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 201 (movie/v13/dataset/cut/V202.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 202 (movie/v13/dataset/cut/V203.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 203 (movie/v13/dataset/cut/V204.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 204 (movie/v13/dataset/cut/V205.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 205 (movie/v13/dataset/cut/V206.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 206 (movie/v13/dataset/cut/V207.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 207 (movie/v13/dataset/cut/V208.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 208 (movie/v13/dataset/cut/V209.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 209 (movie/v13/dataset/cut/V210.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 210 (movie/v13/dataset/cut/V211.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 211 (movie/v13/dataset/cut/V212.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 212 (movie/v13/dataset/cut/V213.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 213 (movie/v13/dataset/cut/V214.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 214 (movie/v13/dataset/cut/V215.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 215 (movie/v13/dataset/cut/V216.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 216 (movie/v13/dataset/cut/V217.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 217 (movie/v13/dataset/cut/V218.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 218 (movie/v13/dataset/cut/V219.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 219 (movie/v13/dataset/cut/V220.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 220 (movie/v13/dataset/cut/V221.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 221 (movie/v13/dataset/cut/V222.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 222 (movie/v13/dataset/cut/V223.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 223 (movie/v13/dataset/cut/V224.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 224 (movie/v13/dataset/cut/V225.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 225 (movie/v13/dataset/cut/V226.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 226 (movie/v13/dataset/cut/V227.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 227 (movie/v13/dataset/cut/V228.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 228 (movie/v13/dataset/cut/V229.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 229 (movie/v13/dataset/cut/V230.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 230 (movie/v13/dataset/cut/V231.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 231 (movie/v13/dataset/cut/V232.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 232 (movie/v13/dataset/cut/V233.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 233 (movie/v13/dataset/cut/V234.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 234 (movie/v13/dataset/cut/V235.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 235 (movie/v13/dataset/cut/V236.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 236 (movie/v13/dataset/cut/V237.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 237 (movie/v13/dataset/cut/V238.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 238 (movie/v13/dataset/cut/V239.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 239 (movie/v13/dataset/cut/V240.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 240 (movie/v13/dataset/cut/V241.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 241 (movie/v13/dataset/cut/V242.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 242 (movie/v13/dataset/cut/V243.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 243 (movie/v13/dataset/cut/V244.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 244 (movie/v13/dataset/cut/V245.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 245 (movie/v13/dataset/cut/V246.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 246 (movie/v13/dataset/cut/V247.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 247 (movie/v13/dataset/cut/V248.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 248 (movie/v13/dataset/cut/V249.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 249 (movie/v13/dataset/cut/V250.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 250 (movie/v13/dataset/cut/V251.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 251 (movie/v13/dataset/cut/V252.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 252 (movie/v13/dataset/cut/V253.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 253 (movie/v13/dataset/cut/V254.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 254 (movie/v13/dataset/cut/V255.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 255 (movie/v13/dataset/cut/V256.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "Video 256 (movie/v13/dataset/cut/V257.mp4): total_frames=6, cuts-1@frames=[2]\n",
      "\n",
      "Processed 257 videos (valid 257/257), extracted 12519 frames.\n",
      "Generated 12262 frame pairs: 373 cuts (positive) and 11889 non-cuts (negative).\n",
      "Pos ratio: 0.030419 | Neg ratio: 0.969581\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import openpyxl\n",
    "\n",
    "# Paths and parameters\n",
    "video_dir = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut\"              # Directory containing V001.mp4, V002.mp4, ...\n",
    "excel_file = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut.xlsx\"        # Excel file with annotations\n",
    "frame_size = (224, 224)                                        # resize frames for CNN input\n",
    "\n",
    "# -------- 读取 Excel（用 openpyxl，替代 pandas） --------\n",
    "wb = openpyxl.load_workbook(excel_file, data_only=True)\n",
    "ws = wb.active  # 默认第一个工作表\n",
    "\n",
    "rows = list(ws.iter_rows(values_only=True))\n",
    "if len(rows) == 0:\n",
    "    raise RuntimeError(\"Excel 里没有任何行！\")\n",
    "\n",
    "# 第 1 行：全局帧率（例如 24）\n",
    "fps_row = rows[0]\n",
    "\n",
    "def get_fps_from_row(r, default=24.0):\n",
    "    for cell in r:\n",
    "        if cell is None:\n",
    "            continue\n",
    "        if isinstance(cell, (int, float)):\n",
    "            return float(cell)\n",
    "        if isinstance(cell, str):\n",
    "            s = cell.strip()\n",
    "            if s == \"\" or s.lower() == \"none\":\n",
    "                continue\n",
    "            try:\n",
    "                return float(s)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return float(default)\n",
    "\n",
    "fps = get_fps_from_row(fps_row, default=24.0)\n",
    "print(f\"Using FPS from Excel first row: {fps}\")\n",
    "\n",
    "# 后面的每一行对应一个视频：这一行的每一列都是一个 cut 的 timecode\n",
    "data_rows = rows[1:]\n",
    "\n",
    "# rows[i] 对应 V00{i+1}\n",
    "video_files = sorted(glob.glob(f\"{video_dir}/V*.mp4\"))\n",
    "assert len(video_files) == len(data_rows), \\\n",
    "    f\"Mismatch between number of videos ({len(video_files)}) and Excel data rows ({len(data_rows)})\"\n",
    "\n",
    "\n",
    "def timecode_to_frame(tc, fps):\n",
    "    \"\"\"\n",
    "    把 Excel 里的单个标注值统一本成帧号：\n",
    "    - None / 'none' / '' → None（表示没有 cut）\n",
    "    - 纯数字字符串 / 数字 → 直接当作帧号\n",
    "    - 'ss:ff' → 秒 + 帧（例如 01:12 在 24fps 下就是 36）\n",
    "    - 'hh:mm:ss' → 标准时码（按秒算：((h*60+m)*60+s)*fps）\n",
    "    \"\"\"\n",
    "    if tc is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(tc, (int, float)):\n",
    "        return int(tc)\n",
    "\n",
    "    if isinstance(tc, str):\n",
    "        s = tc.strip()\n",
    "        if s == \"\" or s.lower() == \"none\":\n",
    "            return None\n",
    "\n",
    "        if s.isdigit():\n",
    "            return int(s)\n",
    "\n",
    "        if \":\" in s:\n",
    "            parts = s.split(\":\")\n",
    "            try:\n",
    "                if len(parts) == 2:\n",
    "                    sec = int(parts[0])\n",
    "                    frm = int(parts[1])\n",
    "                    return int(sec * fps + frm)\n",
    "                elif len(parts) == 3:\n",
    "                    h = int(parts[0])\n",
    "                    m = int(parts[1])\n",
    "                    sec = int(parts[2])\n",
    "                    total_sec = h * 3600 + m * 60 + sec\n",
    "                    return int(total_sec * fps)\n",
    "                else:\n",
    "                    return None\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# -------- 准备数据容器（这些变量后面 Cell2 会用） --------\n",
    "video_frames = []                 # list[list[np.ndarray]]: 每个视频的全部帧（已resize）\n",
    "boundary_pairs = []               # list[tuple]: (vid_idx, i, label)\n",
    "boundary_pairs_by_video = []      # list[list[tuple]]: 每个视频自己的pairs（便于后面更聪明采样）\n",
    "cut_indices_list = []             # list[list[int]]: 每个视频的 cut_indices（i位置，表示 i 和 i+1 之间有切）\n",
    "total_frames_list = []            # list[int]: 每个视频总帧数\n",
    "valid_video_mask = []             # list[bool]: 视频是否有效（>=2帧）\n",
    "video_paths = list(video_files)   # 备份一下路径，后面打印/定位很方便\n",
    "\n",
    "# -------- 遍历视频 + 对应 Excel 行 --------\n",
    "for vid_idx, (video_path, row) in enumerate(zip(video_files, data_rows)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        frame_resized = cv2.resize(frame, frame_size)\n",
    "        frames.append(frame_resized)\n",
    "        success, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    video_frames.append(frames)\n",
    "    total_frames = len(frames)\n",
    "    total_frames_list.append(total_frames)\n",
    "\n",
    "    if total_frames <= 1:\n",
    "        valid_video_mask.append(False)\n",
    "        boundary_pairs_by_video.append([])\n",
    "        cut_indices_list.append([])\n",
    "        print(f\"Warning: video {video_path} has {total_frames} frame(s), skip boundary generation.\")\n",
    "        continue\n",
    "\n",
    "    valid_video_mask.append(True)\n",
    "\n",
    "    raw_values = list(row) if row is not None else []\n",
    "\n",
    "    cut_indices = []\n",
    "    for v in raw_values:\n",
    "        frame_idx = timecode_to_frame(v, fps)\n",
    "        if frame_idx is None:\n",
    "            continue\n",
    "\n",
    "        # Excel 标的是切后镜头起始帧 (B-start)\n",
    "        # SBD 的 cut 应标在 (B-1, B) 之间 → 对应 pair i = B-1\n",
    "        if frame_idx > 0:\n",
    "            frame_idx = frame_idx - 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        frame_idx = int(frame_idx)\n",
    "        frame_idx = max(0, min(frame_idx, total_frames - 2))\n",
    "        cut_indices.append(frame_idx)\n",
    "\n",
    "    cut_indices = sorted(set(cut_indices))\n",
    "    cut_indices_list.append(cut_indices)\n",
    "\n",
    "    print(f\"Video {vid_idx} ({video_path}): total_frames={total_frames}, cuts-1@frames={cut_indices}\")\n",
    "\n",
    "    cut_set = set(cut_indices)\n",
    "\n",
    "    per_video_pairs = []\n",
    "    for i in range(total_frames - 1):\n",
    "        label = 1 if i in cut_set else 0\n",
    "        tup = (vid_idx, i, label)\n",
    "        boundary_pairs.append(tup)\n",
    "        per_video_pairs.append(tup)\n",
    "\n",
    "    boundary_pairs_by_video.append(per_video_pairs)\n",
    "\n",
    "# -------- 关键全局变量（Cell2 会直接用到） --------\n",
    "num_videos = len(video_files)\n",
    "\n",
    "# -------- 数据统计 --------\n",
    "num_pairs = len(boundary_pairs)\n",
    "num_cuts = sum(1 for _, _, lbl in boundary_pairs if lbl == 1)\n",
    "num_noncuts = num_pairs - num_cuts\n",
    "\n",
    "total_extracted_frames = sum(len(frames) for frames in video_frames)\n",
    "num_valid_videos = sum(1 for v in valid_video_mask if v)\n",
    "\n",
    "print(f\"\\nProcessed {num_videos} videos (valid {num_valid_videos}/{num_videos}), extracted {total_extracted_frames} frames.\")\n",
    "print(f\"Generated {num_pairs} frame pairs: {num_cuts} cuts (positive) and {num_noncuts} non-cuts (negative).\")\n",
    "\n",
    "# -------- 可选：把全局正负比例也存一下，后续算pos_weight更方便 --------\n",
    "pos_count = num_cuts\n",
    "neg_count = num_noncuts\n",
    "pos_ratio = (pos_count / num_pairs) if num_pairs > 0 else 0.0\n",
    "neg_ratio = (neg_count / num_pairs) if num_pairs > 0 else 0.0\n",
    "print(f\"Pos ratio: {pos_ratio:.6f} | Neg ratio: {neg_ratio:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bdaa218-73cd-446b-8e0d-13d47e3c2c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Split] train_vids=244 test_vids=13\n",
      "[Pool] train_pos=350 train_neg=11020 test_total=892\n"
     ]
    }
   ],
   "source": [
    "# ============= Cell2: Dataset + 按视频划分 + 正例全量/负例动态抽样（每epoch不一样） =============\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ShotBoundaryDataset(Dataset):\n",
    "    def __init__(self, pairs, video_frames):\n",
    "        self.pairs = pairs\n",
    "        self.video_frames = video_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_idx, frame_idx, label = self.pairs[idx]\n",
    "        frameA = self.video_frames[vid_idx][frame_idx]\n",
    "        frameB = self.video_frames[vid_idx][frame_idx + 1]\n",
    "\n",
    "        diff = cv2.absdiff(frameA, frameB)\n",
    "\n",
    "        img_9ch = np.concatenate([frameA, frameB, diff], axis=2).astype(\"float32\") / 255.0\n",
    "        img_9ch_chw = np.transpose(img_9ch, (2, 0, 1))\n",
    "\n",
    "        img_tensor = torch.tensor(img_9ch_chw, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "\n",
    "# ============= 你只需要改这里的采样参数 =============\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "USE_DYNAMIC_NEG_SAMPLING = False       # True=每个epoch动态抽负例；False=全量训练（等同你原来的）\n",
    "NEG_SAMPLING_MODE = \"ratio\"           # \"ratio\" or \"per_pos\"\n",
    "NEG_SAMPLE_RATIO = 0.10               # mode=\"ratio\": 每个epoch抽取负例池的比例（0.1=十分之一）\n",
    "NEG_PER_POS = 5                       # mode=\"per_pos\": 每个epoch负例数 = 正例数 * NEG_PER_POS\n",
    "\n",
    "SEED_SPLIT = 42                       # 训练/测试划分可复现\n",
    "SEED_EPOCH_BASE = 20260118            # 每个epoch采样可复现（不同epoch会不一样）\n",
    "\n",
    "\n",
    "# ============= 划分训练测试（按视频） =============\n",
    "all_video_indices = list(range(num_videos))\n",
    "random.seed(SEED_SPLIT)\n",
    "random.shuffle(all_video_indices)\n",
    "\n",
    "split_idx = int(len(all_video_indices) * 0.95)\n",
    "train_vids = set(all_video_indices[:split_idx])\n",
    "test_vids  = set(all_video_indices[split_idx:])\n",
    "\n",
    "train_pairs_all = [p for p in boundary_pairs if p[0] in train_vids]\n",
    "test_pairs      = [p for p in boundary_pairs if p[0] in test_vids]\n",
    "\n",
    "# 训练池拆正/负\n",
    "train_pos_pairs = [p for p in train_pairs_all if p[2] == 1]\n",
    "train_neg_pairs = [p for p in train_pairs_all if p[2] == 0]\n",
    "\n",
    "# 测试集：永远全量，不做抽样\n",
    "test_dataset = ShotBoundaryDataset(test_pairs, video_frames)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"[Split] train_vids={len(train_vids)} test_vids={len(test_vids)}\")\n",
    "print(f\"[Pool] train_pos={len(train_pos_pairs)} train_neg={len(train_neg_pairs)} test_total={len(test_pairs)}\")\n",
    "\n",
    "\n",
    "def make_train_loader_for_epoch(epoch: int, batch_size: int = BATCH_SIZE, shuffle: bool = True):\n",
    "    \"\"\"\n",
    "    每个epoch动态构造训练集：\n",
    "    - 正例：全量保留（每轮必学）\n",
    "    - 负例：每轮重新随机抽样（每轮都不一样）\n",
    "    \"\"\"\n",
    "    if (not USE_DYNAMIC_NEG_SAMPLING) or (len(train_neg_pairs) == 0):\n",
    "        epoch_pairs = list(train_pairs_all)\n",
    "        rng = None\n",
    "    else:\n",
    "        rng = random.Random(SEED_EPOCH_BASE + int(epoch))\n",
    "\n",
    "        if NEG_SAMPLING_MODE == \"ratio\":\n",
    "            k = int(len(train_neg_pairs) * float(NEG_SAMPLE_RATIO))\n",
    "        elif NEG_SAMPLING_MODE == \"per_pos\":\n",
    "            k = int(len(train_pos_pairs) * int(NEG_PER_POS))\n",
    "        else:\n",
    "            raise ValueError(\"NEG_SAMPLING_MODE must be 'ratio' or 'per_pos'\")\n",
    "\n",
    "        k = max(1, min(k, len(train_neg_pairs)))\n",
    "        neg_sample = rng.sample(train_neg_pairs, k)\n",
    "\n",
    "        epoch_pairs = list(train_pos_pairs) + neg_sample\n",
    "        rng.shuffle(epoch_pairs)\n",
    "\n",
    "    train_dataset_epoch = ShotBoundaryDataset(epoch_pairs, video_frames)\n",
    "    train_loader_epoch  = DataLoader(train_dataset_epoch, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    pos_n = len(train_pos_pairs)\n",
    "    neg_n = len(train_dataset_epoch) - pos_n\n",
    "    raw_pos_weight_epoch = (neg_n / max(1, pos_n))\n",
    "\n",
    "    # 给你一个非常直观的确认：每轮neg数量、raw_pos_weight都会按你的抽样变化\n",
    "    print(f\"[Epoch {epoch}] train_pairs={len(train_dataset_epoch)} (pos {pos_n}, neg {neg_n}) raw_pos_weight_ep={raw_pos_weight_epoch:.4f}\")\n",
    "    return train_loader_epoch, train_dataset_epoch, raw_pos_weight_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66011fa-3e95-48cd-a33a-fc254c4d5a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "raw_pos_weight = 31.873994638069703, used pos_weight = 40.0\n",
      "[Epoch 0] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 0] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 1/100 | loss 0.6723 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.1282 | AUC 0.6826 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.55 bestF1(train) 0.2104 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 1] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 1] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 2/100 | loss 0.6604 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.1822 | AUC 0.7351 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.57 bestF1(train) 0.2413 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 2] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 2] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 3/100 | loss 0.6509 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.2251 | AUC 0.7769 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.60 bestF1(train) 0.2582 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 3] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 3] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 4/100 | loss 0.6441 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.2798 | AUC 0.8011 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.62 bestF1(train) 0.3110 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 4] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 4] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 5/100 | loss 0.6364 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.3367 | AUC 0.8292 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.62 bestF1(train) 0.3659 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 5] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 5] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 6/100 | loss 0.6300 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.3806 | AUC 0.8502 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.62 bestF1(train) 0.3887 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 6] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 6] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 7/100 | loss 0.6235 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.4361 | AUC 0.8735 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.62 bestF1(train) 0.4390 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 7] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 7] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 8/100 | loss 0.6173 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.4937 | AUC 0.8951 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.61 bestF1(train) 0.4881 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 8] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 8] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 9/100 | loss 0.6098 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.5447 | AUC 0.9132 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.61 bestF1(train) 0.5284 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 9] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 9] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 10/100 | loss 0.6047 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.6027 | AUC 0.9306 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.60 bestF1(train) 0.5816 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 10] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 10] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 11/100 | loss 0.5988 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.6558 | AUC 0.9463 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.60 bestF1(train) 0.6299 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 11] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 11] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 12/100 | loss 0.5916 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.7013 | AUC 0.9590 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.6708 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 12] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 12] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 13/100 | loss 0.5876 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.7319 | AUC 0.9666 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.6924 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 13] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 13] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 14/100 | loss 0.5807 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.7589 | AUC 0.9726 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7128 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 14] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 14] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 15/100 | loss 0.5745 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.7781 | AUC 0.9763 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.57 bestF1(train) 0.7336 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 15] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 15] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 16/100 | loss 0.5698 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.7915 | AUC 0.9784 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7485 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 16] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 16] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 17/100 | loss 0.5640 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.7996 | AUC 0.9795 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7574 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 17] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 17] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 18/100 | loss 0.5595 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8078 | AUC 0.9811 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7606 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 18] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 18] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 19/100 | loss 0.5544 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8167 | AUC 0.9820 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7839 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 19] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 19] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 20/100 | loss 0.5495 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8231 | AUC 0.9829 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7858 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 20] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 20] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 21/100 | loss 0.5445 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8287 | AUC 0.9836 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.7920 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 21] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 21] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 22/100 | loss 0.5390 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8333 | AUC 0.9838 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7930 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 22] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 22] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 23/100 | loss 0.5335 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8366 | AUC 0.9836 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.58 bestF1(train) 0.7965 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 23] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 23] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 24/100 | loss 0.5288 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8401 | AUC 0.9842 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8012 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 24] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 24] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 25/100 | loss 0.5249 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8438 | AUC 0.9849 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8048 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 25] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 25] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 26/100 | loss 0.5213 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8466 | AUC 0.9851 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.60 bestF1(train) 0.8019 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 26] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 26] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 27/100 | loss 0.5163 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8481 | AUC 0.9849 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8066 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 27] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 27] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 28/100 | loss 0.5121 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8499 | AUC 0.9852 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8065 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 28] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 28] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 29/100 | loss 0.5088 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8515 | AUC 0.9853 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8065 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 29] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 29] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 30/100 | loss 0.5035 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8528 | AUC 0.9853 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8119 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 30] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 30] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 31/100 | loss 0.4987 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8539 | AUC 0.9850 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8107 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 31] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 31] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 32/100 | loss 0.4949 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8539 | AUC 0.9848 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8101 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 32] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 32] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 33/100 | loss 0.4920 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8534 | AUC 0.9844 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8125 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 33] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 33] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 34/100 | loss 0.4879 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8539 | AUC 0.9841 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8149 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 34] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 34] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 35/100 | loss 0.4844 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8554 | AUC 0.9844 | TP 0 FP 0 TN 11020 FN 350 | pos_pred_rate 0.0000 | best_t(train) 0.59 bestF1(train) 0.8175 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 35] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 35] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 36/100 | loss 0.4804 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8574 | AUC 0.9851 | TP 0 FP 1 TN 11019 FN 350 | pos_pred_rate 0.0001 | best_t(train) 0.60 bestF1(train) 0.8168 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 36] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 36] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 37/100 | loss 0.4762 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8590 | AUC 0.9856 | TP 0 FP 1 TN 11019 FN 350 | pos_pred_rate 0.0001 | best_t(train) 0.60 bestF1(train) 0.8220 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 37] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 37] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 38/100 | loss 0.4735 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8603 | AUC 0.9857 | TP 0 FP 1 TN 11019 FN 350 | pos_pred_rate 0.0001 | best_t(train) 0.60 bestF1(train) 0.8216 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 38] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 38] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 39/100 | loss 0.4699 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8597 | AUC 0.9850 | TP 0 FP 1 TN 11019 FN 350 | pos_pred_rate 0.0001 | best_t(train) 0.61 bestF1(train) 0.8264 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 39] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 39] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 40/100 | loss 0.4671 | F1 0.0000 (P 0.0000, R 0.0000) | AP 0.8567 | AUC 0.9838 | TP 0 FP 1 TN 11019 FN 350 | pos_pred_rate 0.0001 | best_t(train) 0.60 bestF1(train) 0.8204 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 40] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 40] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 41/100 | loss 0.4630 | F1 0.0057 (P 0.5000, R 0.0029) | AP 0.8558 | AUC 0.9831 | TP 1 FP 1 TN 11019 FN 349 | pos_pred_rate 0.0002 | best_t(train) 0.60 bestF1(train) 0.8253 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 41] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 41] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 42/100 | loss 0.4595 | F1 0.0057 (P 0.5000, R 0.0029) | AP 0.8552 | AUC 0.9826 | TP 1 FP 1 TN 11019 FN 349 | pos_pred_rate 0.0002 | best_t(train) 0.60 bestF1(train) 0.8253 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 42] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 42] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 43/100 | loss 0.4564 | F1 0.0057 (P 0.5000, R 0.0029) | AP 0.8562 | AUC 0.9830 | TP 1 FP 1 TN 11019 FN 349 | pos_pred_rate 0.0002 | best_t(train) 0.61 bestF1(train) 0.8290 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 43] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 43] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 44/100 | loss 0.4526 | F1 0.0057 (P 0.5000, R 0.0029) | AP 0.8574 | AUC 0.9832 | TP 1 FP 1 TN 11019 FN 349 | pos_pred_rate 0.0002 | best_t(train) 0.61 bestF1(train) 0.8282 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 44] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 44] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 45/100 | loss 0.4506 | F1 0.0057 (P 0.5000, R 0.0029) | AP 0.8581 | AUC 0.9833 | TP 1 FP 1 TN 11019 FN 349 | pos_pred_rate 0.0002 | best_t(train) 0.61 bestF1(train) 0.8323 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 45] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 45] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 46/100 | loss 0.4461 | F1 0.0057 (P 0.5000, R 0.0029) | AP 0.8589 | AUC 0.9834 | TP 1 FP 1 TN 11019 FN 349 | pos_pred_rate 0.0002 | best_t(train) 0.61 bestF1(train) 0.8308 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 46] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 46] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 47/100 | loss 0.4433 | F1 0.0057 (P 0.5000, R 0.0029) | AP 0.8594 | AUC 0.9836 | TP 1 FP 1 TN 11019 FN 349 | pos_pred_rate 0.0002 | best_t(train) 0.61 bestF1(train) 0.8288 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 47] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 47] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 48/100 | loss 0.4409 | F1 0.0113 (P 0.6667, R 0.0057) | AP 0.8590 | AUC 0.9832 | TP 2 FP 1 TN 11019 FN 348 | pos_pred_rate 0.0003 | best_t(train) 0.61 bestF1(train) 0.8301 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 48] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 48] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 49/100 | loss 0.4384 | F1 0.0169 (P 0.7500, R 0.0086) | AP 0.8590 | AUC 0.9831 | TP 3 FP 1 TN 11019 FN 347 | pos_pred_rate 0.0004 | best_t(train) 0.62 bestF1(train) 0.8315 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 49] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 49] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 50/100 | loss 0.4347 | F1 0.0169 (P 0.7500, R 0.0086) | AP 0.8588 | AUC 0.9830 | TP 3 FP 1 TN 11019 FN 347 | pos_pred_rate 0.0004 | best_t(train) 0.62 bestF1(train) 0.8320 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 50] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 50] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 51/100 | loss 0.4316 | F1 0.0169 (P 0.7500, R 0.0086) | AP 0.8599 | AUC 0.9833 | TP 3 FP 1 TN 11019 FN 347 | pos_pred_rate 0.0004 | best_t(train) 0.62 bestF1(train) 0.8371 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 51] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 51] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 52/100 | loss 0.4286 | F1 0.0169 (P 0.7500, R 0.0086) | AP 0.8604 | AUC 0.9835 | TP 3 FP 1 TN 11019 FN 347 | pos_pred_rate 0.0004 | best_t(train) 0.62 bestF1(train) 0.8346 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 52] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 52] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 53/100 | loss 0.4267 | F1 0.0225 (P 0.8000, R 0.0114) | AP 0.8605 | AUC 0.9832 | TP 4 FP 1 TN 11019 FN 346 | pos_pred_rate 0.0004 | best_t(train) 0.62 bestF1(train) 0.8346 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 53] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 53] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 54/100 | loss 0.4232 | F1 0.0281 (P 0.8333, R 0.0143) | AP 0.8584 | AUC 0.9822 | TP 5 FP 1 TN 11019 FN 345 | pos_pred_rate 0.0005 | best_t(train) 0.62 bestF1(train) 0.8359 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 54] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 54] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 55/100 | loss 0.4222 | F1 0.0391 (P 0.8750, R 0.0200) | AP 0.8591 | AUC 0.9829 | TP 7 FP 1 TN 11019 FN 343 | pos_pred_rate 0.0007 | best_t(train) 0.62 bestF1(train) 0.8326 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 55] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 55] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 56/100 | loss 0.4176 | F1 0.0554 (P 0.9091, R 0.0286) | AP 0.8603 | AUC 0.9830 | TP 10 FP 1 TN 11019 FN 340 | pos_pred_rate 0.0010 | best_t(train) 0.63 bestF1(train) 0.8351 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 56] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 56] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 57/100 | loss 0.4149 | F1 0.0608 (P 0.9167, R 0.0314) | AP 0.8595 | AUC 0.9826 | TP 11 FP 1 TN 11019 FN 339 | pos_pred_rate 0.0011 | best_t(train) 0.63 bestF1(train) 0.8351 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 57] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 57] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 58/100 | loss 0.4128 | F1 0.0661 (P 0.9231, R 0.0343) | AP 0.8598 | AUC 0.9827 | TP 12 FP 1 TN 11019 FN 338 | pos_pred_rate 0.0011 | best_t(train) 0.63 bestF1(train) 0.8351 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 58] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 58] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 59/100 | loss 0.4102 | F1 0.0714 (P 0.9286, R 0.0371) | AP 0.8609 | AUC 0.9831 | TP 13 FP 1 TN 11019 FN 337 | pos_pred_rate 0.0012 | best_t(train) 0.63 bestF1(train) 0.8354 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 59] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 59] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 60/100 | loss 0.4083 | F1 0.0767 (P 0.9333, R 0.0400) | AP 0.8614 | AUC 0.9832 | TP 14 FP 1 TN 11019 FN 336 | pos_pred_rate 0.0013 | best_t(train) 0.63 bestF1(train) 0.8351 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 60] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 60] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 61/100 | loss 0.4070 | F1 0.0820 (P 0.9375, R 0.0429) | AP 0.8615 | AUC 0.9831 | TP 15 FP 1 TN 11019 FN 335 | pos_pred_rate 0.0014 | best_t(train) 0.64 bestF1(train) 0.8364 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 61] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 61] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 62/100 | loss 0.4043 | F1 0.0872 (P 0.9412, R 0.0457) | AP 0.8613 | AUC 0.9831 | TP 16 FP 1 TN 11019 FN 334 | pos_pred_rate 0.0015 | best_t(train) 0.64 bestF1(train) 0.8369 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 62] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 62] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 63/100 | loss 0.4006 | F1 0.1180 (P 0.9565, R 0.0629) | AP 0.8626 | AUC 0.9835 | TP 22 FP 1 TN 11019 FN 328 | pos_pred_rate 0.0020 | best_t(train) 0.65 bestF1(train) 0.8367 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 63] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 63] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 64/100 | loss 0.3991 | F1 0.1230 (P 0.9583, R 0.0657) | AP 0.8634 | AUC 0.9837 | TP 23 FP 1 TN 11019 FN 327 | pos_pred_rate 0.0021 | best_t(train) 0.65 bestF1(train) 0.8359 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 64] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 64] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 65/100 | loss 0.3981 | F1 0.1230 (P 0.9583, R 0.0657) | AP 0.8634 | AUC 0.9837 | TP 23 FP 1 TN 11019 FN 327 | pos_pred_rate 0.0021 | best_t(train) 0.65 bestF1(train) 0.8346 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 65] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 65] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 66/100 | loss 0.3947 | F1 0.1230 (P 0.9583, R 0.0657) | AP 0.8612 | AUC 0.9829 | TP 23 FP 1 TN 11019 FN 327 | pos_pred_rate 0.0021 | best_t(train) 0.63 bestF1(train) 0.8356 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 66] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 66] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 67/100 | loss 0.3927 | F1 0.1230 (P 0.9583, R 0.0657) | AP 0.8585 | AUC 0.9815 | TP 23 FP 1 TN 11019 FN 327 | pos_pred_rate 0.0021 | best_t(train) 0.63 bestF1(train) 0.8316 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 67] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 67] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 68/100 | loss 0.3917 | F1 0.1230 (P 0.9583, R 0.0657) | AP 0.8588 | AUC 0.9817 | TP 23 FP 1 TN 11019 FN 327 | pos_pred_rate 0.0021 | best_t(train) 0.64 bestF1(train) 0.8320 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 68] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 68] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 69/100 | loss 0.3889 | F1 0.1429 (P 0.9643, R 0.0771) | AP 0.8599 | AUC 0.9820 | TP 27 FP 1 TN 11019 FN 323 | pos_pred_rate 0.0025 | best_t(train) 0.65 bestF1(train) 0.8354 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 69] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 69] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 70/100 | loss 0.3859 | F1 0.1478 (P 0.9655, R 0.0800) | AP 0.8613 | AUC 0.9825 | TP 28 FP 1 TN 11019 FN 322 | pos_pred_rate 0.0026 | best_t(train) 0.65 bestF1(train) 0.8377 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 70] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 70] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 71/100 | loss 0.3841 | F1 0.1478 (P 0.9655, R 0.0800) | AP 0.8622 | AUC 0.9829 | TP 28 FP 1 TN 11019 FN 322 | pos_pred_rate 0.0026 | best_t(train) 0.66 bestF1(train) 0.8393 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 71] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 71] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 72/100 | loss 0.3812 | F1 0.1575 (P 0.9677, R 0.0857) | AP 0.8630 | AUC 0.9831 | TP 30 FP 1 TN 11019 FN 320 | pos_pred_rate 0.0027 | best_t(train) 0.66 bestF1(train) 0.8367 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 72] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 72] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 73/100 | loss 0.3800 | F1 0.1623 (P 0.9688, R 0.0886) | AP 0.8630 | AUC 0.9830 | TP 31 FP 1 TN 11019 FN 319 | pos_pred_rate 0.0028 | best_t(train) 0.66 bestF1(train) 0.8403 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 73] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 73] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 74/100 | loss 0.3771 | F1 0.1671 (P 0.9697, R 0.0914) | AP 0.8626 | AUC 0.9829 | TP 32 FP 1 TN 11019 FN 318 | pos_pred_rate 0.0029 | best_t(train) 0.66 bestF1(train) 0.8385 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 74] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 74] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 75/100 | loss 0.3750 | F1 0.1766 (P 0.9714, R 0.0971) | AP 0.8610 | AUC 0.9821 | TP 34 FP 1 TN 11019 FN 316 | pos_pred_rate 0.0031 | best_t(train) 0.66 bestF1(train) 0.8344 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 75] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 75] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 76/100 | loss 0.3743 | F1 0.2000 (P 0.9750, R 0.1114) | AP 0.8618 | AUC 0.9825 | TP 39 FP 1 TN 11019 FN 311 | pos_pred_rate 0.0035 | best_t(train) 0.66 bestF1(train) 0.8367 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 76] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 76] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 77/100 | loss 0.3711 | F1 0.2092 (P 0.9762, R 0.1171) | AP 0.8635 | AUC 0.9830 | TP 41 FP 1 TN 11019 FN 309 | pos_pred_rate 0.0037 | best_t(train) 0.66 bestF1(train) 0.8377 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 77] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 77] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 78/100 | loss 0.3702 | F1 0.2273 (P 0.9783, R 0.1286) | AP 0.8641 | AUC 0.9833 | TP 45 FP 1 TN 11019 FN 305 | pos_pred_rate 0.0040 | best_t(train) 0.67 bestF1(train) 0.8375 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 78] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 78] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 79/100 | loss 0.3679 | F1 0.2317 (P 0.9787, R 0.1314) | AP 0.8638 | AUC 0.9831 | TP 46 FP 1 TN 11019 FN 304 | pos_pred_rate 0.0041 | best_t(train) 0.67 bestF1(train) 0.8393 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 79] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 79] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 80/100 | loss 0.3663 | F1 0.2362 (P 0.9792, R 0.1343) | AP 0.8638 | AUC 0.9830 | TP 47 FP 1 TN 11019 FN 303 | pos_pred_rate 0.0042 | best_t(train) 0.67 bestF1(train) 0.8375 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 80] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 80] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 81/100 | loss 0.3640 | F1 0.2362 (P 0.9792, R 0.1343) | AP 0.8642 | AUC 0.9831 | TP 47 FP 1 TN 11019 FN 303 | pos_pred_rate 0.0042 | best_t(train) 0.67 bestF1(train) 0.8385 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 81] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 81] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 82/100 | loss 0.3628 | F1 0.2406 (P 0.9796, R 0.1371) | AP 0.8643 | AUC 0.9832 | TP 48 FP 1 TN 11019 FN 302 | pos_pred_rate 0.0043 | best_t(train) 0.67 bestF1(train) 0.8385 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 82] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 82] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 83/100 | loss 0.3615 | F1 0.2494 (P 0.9804, R 0.1429) | AP 0.8654 | AUC 0.9835 | TP 50 FP 1 TN 11019 FN 300 | pos_pred_rate 0.0045 | best_t(train) 0.67 bestF1(train) 0.8390 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 83] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 83] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 84/100 | loss 0.3597 | F1 0.2494 (P 0.9804, R 0.1429) | AP 0.8645 | AUC 0.9831 | TP 50 FP 1 TN 11019 FN 300 | pos_pred_rate 0.0045 | best_t(train) 0.67 bestF1(train) 0.8403 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 84] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 84] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 85/100 | loss 0.3571 | F1 0.2494 (P 0.9804, R 0.1429) | AP 0.8632 | AUC 0.9826 | TP 50 FP 1 TN 11019 FN 300 | pos_pred_rate 0.0045 | best_t(train) 0.62 bestF1(train) 0.8369 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 85] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 85] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 86/100 | loss 0.3550 | F1 0.2494 (P 0.9804, R 0.1429) | AP 0.8632 | AUC 0.9825 | TP 50 FP 1 TN 11019 FN 300 | pos_pred_rate 0.0045 | best_t(train) 0.62 bestF1(train) 0.8374 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 86] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 86] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 87/100 | loss 0.3527 | F1 0.2581 (P 0.9811, R 0.1486) | AP 0.8638 | AUC 0.9828 | TP 52 FP 1 TN 11019 FN 298 | pos_pred_rate 0.0047 | best_t(train) 0.65 bestF1(train) 0.8383 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 87] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 87] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 88/100 | loss 0.3536 | F1 0.2581 (P 0.9811, R 0.1486) | AP 0.8631 | AUC 0.9824 | TP 52 FP 1 TN 11019 FN 298 | pos_pred_rate 0.0047 | best_t(train) 0.65 bestF1(train) 0.8401 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 88] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 88] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 89/100 | loss 0.3509 | F1 0.2624 (P 0.9815, R 0.1514) | AP 0.8633 | AUC 0.9825 | TP 53 FP 1 TN 11019 FN 297 | pos_pred_rate 0.0047 | best_t(train) 0.65 bestF1(train) 0.8401 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 89] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 89] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 90/100 | loss 0.3491 | F1 0.2709 (P 0.9821, R 0.1571) | AP 0.8642 | AUC 0.9827 | TP 55 FP 1 TN 11019 FN 295 | pos_pred_rate 0.0049 | best_t(train) 0.65 bestF1(train) 0.8401 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 90] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 90] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 91/100 | loss 0.3475 | F1 0.2709 (P 0.9821, R 0.1571) | AP 0.8649 | AUC 0.9831 | TP 55 FP 1 TN 11019 FN 295 | pos_pred_rate 0.0049 | best_t(train) 0.65 bestF1(train) 0.8380 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 91] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 91] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 92/100 | loss 0.3451 | F1 0.2836 (P 0.9831, R 0.1657) | AP 0.8659 | AUC 0.9834 | TP 58 FP 1 TN 11019 FN 292 | pos_pred_rate 0.0052 | best_t(train) 0.65 bestF1(train) 0.8390 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 92] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 92] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 93/100 | loss 0.3451 | F1 0.2836 (P 0.9831, R 0.1657) | AP 0.8659 | AUC 0.9833 | TP 58 FP 1 TN 11019 FN 292 | pos_pred_rate 0.0052 | best_t(train) 0.66 bestF1(train) 0.8378 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 93] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 93] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 94/100 | loss 0.3420 | F1 0.2836 (P 0.9831, R 0.1657) | AP 0.8661 | AUC 0.9834 | TP 58 FP 1 TN 11019 FN 292 | pos_pred_rate 0.0052 | best_t(train) 0.66 bestF1(train) 0.8396 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 94] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 94] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 95/100 | loss 0.3409 | F1 0.2920 (P 0.9836, R 0.1714) | AP 0.8669 | AUC 0.9837 | TP 60 FP 1 TN 11019 FN 290 | pos_pred_rate 0.0054 | best_t(train) 0.66 bestF1(train) 0.8401 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 95] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 95] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 96/100 | loss 0.3394 | F1 0.2920 (P 0.9836, R 0.1714) | AP 0.8668 | AUC 0.9836 | TP 60 FP 1 TN 11019 FN 290 | pos_pred_rate 0.0054 | best_t(train) 0.66 bestF1(train) 0.8401 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 96] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 96] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 97/100 | loss 0.3386 | F1 0.3002 (P 0.9841, R 0.1771) | AP 0.8664 | AUC 0.9835 | TP 62 FP 1 TN 11019 FN 288 | pos_pred_rate 0.0055 | best_t(train) 0.66 bestF1(train) 0.8401 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 97] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 97] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 98/100 | loss 0.3363 | F1 0.3084 (P 0.9846, R 0.1829) | AP 0.8660 | AUC 0.9833 | TP 64 FP 1 TN 11019 FN 286 | pos_pred_rate 0.0057 | best_t(train) 0.66 bestF1(train) 0.8401 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 98] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 98] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 99/100 | loss 0.3345 | F1 0.3084 (P 0.9846, R 0.1829) | AP 0.8657 | AUC 0.9832 | TP 64 FP 1 TN 11019 FN 286 | pos_pred_rate 0.0057 | best_t(train) 0.66 bestF1(train) 0.8418 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "[Epoch 99] train_pairs=11370 (pos 350, neg 11020) raw_pos_weight_ep=31.4857\n",
      "[Epoch 99] seed_for_neg_sampling = None\n",
      "[Linear] Epoch 100/100 | loss 0.3336 | F1 0.3084 (P 0.9846, R 0.1829) | AP 0.8654 | AUC 0.9829 | TP 64 FP 1 TN 11019 FN 286 | pos_pred_rate 0.0057 | best_t(train) 0.66 bestF1(train) 0.8418 | pos_weight 40.00 (raw_ep 31.49) | train_pairs 11370 (pos 350, neg 11020) | neg_sampling False ratio ratio 0.1 per_pos 5\n",
      "Finished training Linear Baseline model.\n",
      "\n",
      "[Linear] FINAL TEST (threshold=0.95) => F1 0.2963 (P 1.0000, R 0.1739) | AP 0.8465 | AUC 0.9730 | TP 4 FP 0 TN 869 FN 19\n",
      "\n",
      "Shot Boundary Detection - Classification Report (TEST):\n",
      "precision    recall  f1-score   support\n",
      "Non-cut     0.9786   1.0000   0.9892     869\n",
      "Cut         1.0000   0.1739   0.2963      23\n",
      "\n",
      "accuracy                        0.9787     892\n",
      "\n",
      "Saved metrics Excel to: movie/reports/01192309_e100_w40_linear/boundary_train_metrics_20260119_230935.xlsx\n",
      "[Report] Folder: movie/reports/01192309_e100_w40_linear\n",
      "[Model] Saved state_dict to: movie/reports/01192309_e100_w40_linear/linear_model_20260119_230935.pt\n",
      "[Model] Saved checkpoint to: movie/reports/01192309_e100_w40_linear/linear_ckpt_20260119_230935.pth\n"
     ]
    }
   ],
   "source": [
    "# ============= Cell3-L: Linear Baseline 训练（1层网络：Pool + Linear）+ 每Epoch输出多指标 + 写Excel =============\n",
    "\n",
    "import os\n",
    "import platform\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo  # py>=3.9\n",
    "    _TZ = ZoneInfo(\"Asia/BeiJing\")\n",
    "except Exception:\n",
    "    _TZ = None\n",
    "\n",
    "# ===== 简单版 classification_report（沿用你的）=====\n",
    "def simple_classification_report(y_true, y_pred, target_names):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    n_classes = len(target_names)\n",
    "    lines = []\n",
    "    acc = (y_true == y_pred).sum() / len(y_true) if len(y_true) > 0 else 0.0\n",
    "    lines.append(\"precision    recall  f1-score   support\")\n",
    "    for i in range(n_classes):\n",
    "        name = target_names[i]\n",
    "        true_i = (y_true == i)\n",
    "        pred_i = (y_pred == i)\n",
    "        tp = np.logical_and(true_i, pred_i).sum()\n",
    "        fp = np.logical_and(~true_i, pred_i).sum()\n",
    "        fn = np.logical_and(true_i, ~pred_i).sum()\n",
    "        support = true_i.sum()\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        lines.append(f\"{name:10s}  {precision:0.4f}   {recall:0.4f}   {f1:0.4f}   {support:5d}\")\n",
    "    lines.append(f\"\\naccuracy                        {acc:0.4f}   {len(y_true):5d}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ===== 二分类指标（沿用你的）=====\n",
    "def _safe_div(a, b):\n",
    "    return float(a) / float(b) if b else 0.0\n",
    "\n",
    "def binary_metrics_from_probs(y_true, prob_pos, threshold=0.95):\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "    prob_pos = np.asarray(prob_pos, dtype=np.float64)\n",
    "    y_pred = (prob_pos >= threshold).astype(np.int64)\n",
    "\n",
    "    tp = int(np.sum((y_true == 1) & (y_pred == 1)))\n",
    "    fp = int(np.sum((y_true == 0) & (y_pred == 1)))\n",
    "    tn = int(np.sum((y_true == 0) & (y_pred == 0)))\n",
    "    fn = int(np.sum((y_true == 1) & (y_pred == 0)))\n",
    "\n",
    "    precision = _safe_div(tp, tp + fp)\n",
    "    recall    = _safe_div(tp, tp + fn)\n",
    "    f1        = _safe_div(2 * precision * recall, precision + recall)\n",
    "    acc       = _safe_div(tp + tn, tp + tn + fp + fn)\n",
    "\n",
    "    pos_pred_rate = _safe_div(tp + fp, len(y_true))\n",
    "\n",
    "    avg_prob_pos = float(np.mean(prob_pos[y_true == 1])) if np.any(y_true == 1) else 0.0\n",
    "    avg_prob_neg = float(np.mean(prob_pos[y_true == 0])) if np.any(y_true == 0) else 0.0\n",
    "\n",
    "    return {\n",
    "        \"threshold\": float(threshold),\n",
    "        \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn,\n",
    "        \"precision\": precision, \"recall\": recall, \"f1\": f1, \"acc\": acc,\n",
    "        \"pos_pred_rate\": pos_pred_rate,\n",
    "        \"avg_prob_pos\": avg_prob_pos,\n",
    "        \"avg_prob_neg\": avg_prob_neg,\n",
    "    }\n",
    "\n",
    "def average_precision_score(y_true, prob_pos):\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "    prob_pos = np.asarray(prob_pos, dtype=np.float64)\n",
    "    pos_count = int(np.sum(y_true == 1))\n",
    "    if pos_count == 0:\n",
    "        return 0.0\n",
    "    order = np.argsort(-prob_pos)\n",
    "    y_sorted = y_true[order]\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    precisions_at_hits = []\n",
    "    for i in range(len(y_sorted)):\n",
    "        if y_sorted[i] == 1:\n",
    "            tp += 1\n",
    "            precisions_at_hits.append(tp / (tp + fp))\n",
    "        else:\n",
    "            fp += 1\n",
    "    return float(np.sum(precisions_at_hits) / pos_count)\n",
    "\n",
    "def roc_auc_score_rank(y_true, prob_pos):\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "    prob_pos = np.asarray(prob_pos, dtype=np.float64)\n",
    "    n_pos = int(np.sum(y_true == 1))\n",
    "    n_neg = int(np.sum(y_true == 0))\n",
    "    if n_pos == 0 or n_neg == 0:\n",
    "        return 0.0\n",
    "\n",
    "    order = np.argsort(prob_pos)\n",
    "    ranks = np.empty_like(order, dtype=np.float64)\n",
    "    ranks[order] = np.arange(1, len(prob_pos) + 1, dtype=np.float64)\n",
    "\n",
    "    sorted_scores = prob_pos[order]\n",
    "    i = 0\n",
    "    while i < len(sorted_scores):\n",
    "        j = i\n",
    "        while j + 1 < len(sorted_scores) and sorted_scores[j + 1] == sorted_scores[i]:\n",
    "            j += 1\n",
    "        if j > i:\n",
    "            avg_rank = float(np.mean(ranks[order[i:j+1]]))\n",
    "            ranks[order[i:j+1]] = avg_rank\n",
    "        i = j + 1\n",
    "\n",
    "    sum_ranks_pos = float(np.sum(ranks[y_true == 1]))\n",
    "    auc = (sum_ranks_pos - n_pos * (n_pos + 1) / 2.0) / (n_pos * n_neg)\n",
    "    return float(auc)\n",
    "\n",
    "def find_best_threshold_f1(y_true, prob_pos, num_thresholds=101):\n",
    "    best_t = 0.5\n",
    "    best_f1 = -1.0\n",
    "    for k in range(num_thresholds):\n",
    "        t = k / (num_thresholds - 1)\n",
    "        m = binary_metrics_from_probs(y_true, prob_pos, threshold=t)\n",
    "        if m[\"f1\"] > best_f1:\n",
    "            best_f1 = m[\"f1\"]\n",
    "            best_t = t\n",
    "    return float(best_t), float(best_f1)\n",
    "\n",
    "# ===== 设备 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ===== Linear Baseline：无参数池化 + 1层Linear（唯一可学习层）=====\n",
    "class BoundaryLinearBaseline(nn.Module):\n",
    "    def __init__(self, in_ch=9, pool_hw=16):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d((pool_hw, pool_hw))  # 无参数\n",
    "        self.fc = nn.Linear(in_ch * pool_hw * pool_hw, 2)     # 仅这一层有参数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "baseline_model = BoundaryLinearBaseline(in_ch=9, pool_hw=16).to(device)\n",
    "\n",
    "# ===== 类别不平衡权重：保持你原逻辑（用全量统计的 num_cuts/num_noncuts）=====\n",
    "#if num_cuts > 0:\n",
    "    #raw_pos_weight = num_noncuts / num_cuts\n",
    "    # 你 CNN 里手动写 pos_weight=90，这里也沿用（对比更“同条件”）\n",
    "    #pos_weight = 40.0\n",
    "#else:\n",
    "    #raw_pos_weight = None\n",
    "    #pos_weight = 1.0\n",
    "\n",
    "\n",
    "# ===== 和你一致：POS_WEIGHT_MODE 仍保留，但默认 fixed（也就是不随epoch变）=====\n",
    "POS_WEIGHT_MODE = \"fixed\"      # \"fixed\" or \"epoch\"\n",
    "POS_WEIGHT_EPOCH_MAX = 40.0    # epoch模式上限\n",
    "threshold_default = 0.95\n",
    "pos_weight = 40.0\n",
    "raw_pos_weight = num_noncuts / num_cuts\n",
    "print(f\"raw_pos_weight = {num_noncuts / num_cuts if num_cuts > 0 else 'NA'}, used pos_weight = {pos_weight}\")\n",
    "\n",
    "# ===== 优化器：保持简单（你说不用考虑学习好不好，就是对照）=====\n",
    "lr_init = 1e-5\n",
    "optimizer_b = optim.Adam(baseline_model.parameters(), lr=lr_init)\n",
    "\n",
    "def get_system_info():\n",
    "    info = {}\n",
    "    info[\"time_start\"] = datetime.now(_TZ).strftime(\"%Y-%m-%d %H:%M:%S %Z\") if _TZ else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    info[\"python_version\"] = platform.python_version()\n",
    "    info[\"platform\"] = platform.platform()\n",
    "    info[\"processor\"] = platform.processor()\n",
    "    info[\"torch_version\"] = torch.__version__\n",
    "    info[\"cuda_available\"] = str(torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            info[\"cuda_device_count\"] = str(torch.cuda.device_count())\n",
    "            info[\"cuda_device_name_0\"] = torch.cuda.get_device_name(0)\n",
    "        except Exception:\n",
    "            info[\"cuda_device_count\"] = \"NA\"\n",
    "            info[\"cuda_device_name_0\"] = \"NA\"\n",
    "    else:\n",
    "        info[\"cuda_device_count\"] = \"0\"\n",
    "        info[\"cuda_device_name_0\"] = \"NA\"\n",
    "    info[\"device_used\"] = str(device)\n",
    "    return info\n",
    "\n",
    "run_info = get_system_info()\n",
    "\n",
    "# ===== 训练 =====\n",
    "epochs = 50  # 你要对比的话，可改成跟CNN同样轮数\n",
    "epoch_rows = []\n",
    "global_step = 0\n",
    "t0 = time.time()\n",
    "\n",
    "baseline_model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # 每个epoch动态构造 train_loader（来自Cell2）\n",
    "    train_loader, train_dataset, raw_pos_weight_epoch = make_train_loader_for_epoch(\n",
    "        epoch, batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "\n",
    "    seed_epoch = (int(SEED_EPOCH_BASE) + int(epoch)) if USE_DYNAMIC_NEG_SAMPLING else None\n",
    "    print(f\"[Epoch {epoch}] seed_for_neg_sampling = {seed_epoch}\")\n",
    "\n",
    "    # 每epoch选择 used_pos_weight（与你CNN一致写法）\n",
    "    if POS_WEIGHT_MODE == \"fixed\":\n",
    "        used_pos_weight_epoch = float(pos_weight)\n",
    "    elif POS_WEIGHT_MODE == \"epoch\":\n",
    "        used_pos_weight_epoch = float(min(raw_pos_weight_epoch, POS_WEIGHT_EPOCH_MAX))\n",
    "    else:\n",
    "        used_pos_weight_epoch = float(pos_weight)  # 不可用时兜底\n",
    "\n",
    "    # CrossEntropyLoss(weight=[noncut, cut])（与你CNN一致）\n",
    "    class_weights = torch.tensor([1.0, used_pos_weight_epoch], dtype=torch.float32).to(device)\n",
    "    criterion_b = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    y_true_ep = []\n",
    "    prob_pos_ep = []\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer_b.zero_grad()\n",
    "        outputs = baseline_model(imgs)   # logits [B,2]\n",
    "        loss = criterion_b(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_b.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        global_step += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            prob_pos_ep.extend(probs.detach().cpu().numpy().tolist())\n",
    "            y_true_ep.extend(labels.detach().cpu().numpy().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    m = binary_metrics_from_probs(y_true_ep, prob_pos_ep, threshold=threshold_default)\n",
    "    ap = average_precision_score(y_true_ep, prob_pos_ep)\n",
    "    auc = roc_auc_score_rank(y_true_ep, prob_pos_ep)\n",
    "    best_t, best_f1 = find_best_threshold_f1(y_true_ep, prob_pos_ep, num_thresholds=101)\n",
    "\n",
    "    lr_now = optimizer_b.param_groups[0].get(\"lr\", None)\n",
    "\n",
    "    print(\n",
    "        f\"[Linear] Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"loss {epoch_loss:.4f} | \"\n",
    "        f\"F1 {m['f1']:.4f} (P {m['precision']:.4f}, R {m['recall']:.4f}) | \"\n",
    "        f\"AP {ap:.4f} | AUC {auc:.4f} | \"\n",
    "        f\"TP {m['tp']} FP {m['fp']} TN {m['tn']} FN {m['fn']} | \"\n",
    "        f\"pos_pred_rate {m['pos_pred_rate']:.4f} | \"\n",
    "        f\"best_t(train) {best_t:.2f} bestF1(train) {best_f1:.4f} | \"\n",
    "        f\"pos_weight {used_pos_weight_epoch:.2f} (raw_ep {raw_pos_weight_epoch:.2f}) | \"\n",
    "        f\"train_pairs {len(train_loader.dataset)} \"\n",
    "        f\"(pos {len(train_pos_pairs)}, neg {len(train_loader.dataset)-len(train_pos_pairs)}) | \"\n",
    "        f\"neg_sampling {USE_DYNAMIC_NEG_SAMPLING} {NEG_SAMPLING_MODE} \"\n",
    "        f\"ratio {NEG_SAMPLE_RATIO} per_pos {NEG_PER_POS}\"\n",
    "    )\n",
    "\n",
    "    # ===== epoch_rows：列名/顺序对齐你CNN Cell3 的写法 =====\n",
    "    epoch_rows.append({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"global_step\": global_step,\n",
    "        \"loss\": float(epoch_loss),\n",
    "        \"threshold\": float(threshold_default),\n",
    "        \"precision\": float(m[\"precision\"]),\n",
    "        \"recall\": float(m[\"recall\"]),\n",
    "        \"f1\": float(m[\"f1\"]),\n",
    "        \"acc\": float(m[\"acc\"]),\n",
    "        \"tp\": int(m[\"tp\"]),\n",
    "        \"fp\": int(m[\"fp\"]),\n",
    "        \"tn\": int(m[\"tn\"]),\n",
    "        \"fn\": int(m[\"fn\"]),\n",
    "        \"pos_pred_rate\": float(m[\"pos_pred_rate\"]),\n",
    "        \"avg_prob_pos\": float(m[\"avg_prob_pos\"]),\n",
    "        \"avg_prob_neg\": float(m[\"avg_prob_neg\"]),\n",
    "        \"pr_auc_ap\": float(ap),\n",
    "        \"roc_auc\": float(auc),\n",
    "        \"best_threshold_train\": float(best_t),\n",
    "        \"best_f1_train\": float(best_f1),\n",
    "        \"lr\": float(lr_now) if lr_now is not None else 0.0,\n",
    "\n",
    "        # ===== 保留原字段含义 =====\n",
    "        \"pos_weight\": float(pos_weight),\n",
    "        \"raw_pos_weight\": float(raw_pos_weight) if raw_pos_weight is not None else 0.0,\n",
    "        \"weight_noncut\": float(class_weights[0].item()) if class_weights is not None else 0.0,\n",
    "        \"weight_cut\": float(class_weights[1].item()) if class_weights is not None else 0.0,\n",
    "\n",
    "        # ===== 追加字段（对齐你CNN的 extra_cols）=====\n",
    "        \"train_pairs_epoch\": int(len(train_loader.dataset)) if train_loader is not None else 0,\n",
    "        \"raw_pos_weight_epoch\": float(raw_pos_weight_epoch) if raw_pos_weight_epoch is not None else 0.0,\n",
    "        \"pos_weight_mode\": str(POS_WEIGHT_MODE) if POS_WEIGHT_MODE is not None else \"unavailable\",\n",
    "        \"pos_weight_used_epoch\": float(used_pos_weight_epoch) if used_pos_weight_epoch is not None else 0.0,\n",
    "        \"neg_sampling_enabled\": bool(USE_DYNAMIC_NEG_SAMPLING),\n",
    "        \"neg_sampling_mode\": str(NEG_SAMPLING_MODE) if NEG_SAMPLING_MODE is not None else \"unavailable\",\n",
    "        \"neg_sample_ratio\": float(NEG_SAMPLE_RATIO) if NEG_SAMPLE_RATIO is not None else 0.0,\n",
    "        \"neg_per_pos\": int(NEG_PER_POS) if NEG_PER_POS is not None else 0,\n",
    "    })\n",
    "\n",
    "print(\"Finished training Linear Baseline model.\")\n",
    "t_train = time.time() - t0\n",
    "\n",
    "# ===== 最终测试（按你CNN Cell3：test_loader 是Cell2里做的视频级切分后的全量）=====\n",
    "baseline_model.eval()\n",
    "y_true_b, prob_pos_b, y_pred_b = [], [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = baseline_model(imgs)                 # logits [B,2]\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]    # P(cut)\n",
    "        pred = (probs >= threshold_default).long()\n",
    "\n",
    "        y_true_b.extend(labels.detach().cpu().numpy().tolist())\n",
    "        prob_pos_b.extend(probs.detach().cpu().numpy().tolist())\n",
    "        y_pred_b.extend(pred.detach().cpu().numpy().tolist())\n",
    "\n",
    "m_test = binary_metrics_from_probs(y_true_b, prob_pos_b, threshold=threshold_default)\n",
    "ap_test = average_precision_score(y_true_b, prob_pos_b)\n",
    "auc_test = roc_auc_score_rank(y_true_b, prob_pos_b)\n",
    "\n",
    "print(\"\\n[Linear] FINAL TEST (threshold=0.95) => \"\n",
    "      f\"F1 {m_test['f1']:.4f} (P {m_test['precision']:.4f}, R {m_test['recall']:.4f}) | \"\n",
    "      f\"AP {ap_test:.4f} | AUC {auc_test:.4f} | \"\n",
    "      f\"TP {m_test['tp']} FP {m_test['fp']} TN {m_test['tn']} FN {m_test['fn']}\")\n",
    "\n",
    "print(\"\\nShot Boundary Detection - Classification Report (TEST):\")\n",
    "print(simple_classification_report(y_true_b, y_pred_b, target_names=[\"Non-cut\", \"Cut\"]))\n",
    "\n",
    "# ===== 写入 Excel 到 movie/reports，结构对齐你CNN Cell3 =====\n",
    "base_dir = \"movie/reports\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "ts_folder = datetime.now(_TZ).strftime(\"%m%d%H%M\") if _TZ else datetime.now().strftime(\"%m%d%H%M\")\n",
    "\n",
    "# 保持你原来的命名风格：{time}_e{epochs}_w{pos_weight}\n",
    "# 但为了区分CNN vs Linear，追加一个 suffix，不改变你程序抓 e/w 的方式\n",
    "REPORT_FOLDER_NAME = f\"{ts_folder}_e{epochs}_w{int(pos_weight)}_linear\"\n",
    "REPORT_DIR = os.path.join(base_dir, REPORT_FOLDER_NAME)\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "ts = datetime.now(_TZ).strftime(\"%Y%m%d_%H%M%S\") if _TZ else datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(REPORT_DIR, f\"boundary_train_metrics_{ts}.xlsx\")\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "\n",
    "# Sheet 1: run_info（对齐你CNN的键）\n",
    "ws0 = wb.active\n",
    "ws0.title = \"run_info\"\n",
    "ws0.append([\"key\", \"value\"])\n",
    "for k, v in run_info.items():\n",
    "    ws0.append([k, str(v)])\n",
    "\n",
    "ws0.append([\"\"])\n",
    "ws0.append([\"model_name\", \"BoundaryLinearBaseline\"])\n",
    "ws0.append([\"epochs\", str(epochs)])\n",
    "ws0.append([\"train_seconds\", f\"{t_train:.3f}\"])\n",
    "ws0.append([\"threshold_default\", str(threshold_default)])\n",
    "ws0.append([\"optimizer\", \"Adam\"])\n",
    "ws0.append([\"lr_init\", str(lr_init)])\n",
    "ws0.append([\"loss\", \"CrossEntropyLoss(weighted)\"])\n",
    "ws0.append([\"class_weight_noncut\", str(float(1.0))])\n",
    "ws0.append([\"class_weight_cut\", str(float(pos_weight))])\n",
    "ws0.append([\"raw_pos_weight\", str(raw_pos_weight) if raw_pos_weight is not None else \"0\"])\n",
    "ws0.append([\"pos_weight_used\", str(pos_weight)])\n",
    "\n",
    "ws0.append([\"\"])\n",
    "ws0.append([\"pos_weight_mode\", str(POS_WEIGHT_MODE) if POS_WEIGHT_MODE is not None else \"unavailable\"])\n",
    "ws0.append([\"pos_weight_epoch_max\", str(POS_WEIGHT_EPOCH_MAX) if POS_WEIGHT_EPOCH_MAX is not None else \"0\"])\n",
    "ws0.append([\"neg_sampling_enabled\", str(USE_DYNAMIC_NEG_SAMPLING)])\n",
    "ws0.append([\"neg_sampling_mode\", str(NEG_SAMPLING_MODE) if NEG_SAMPLING_MODE is not None else \"unavailable\"])\n",
    "ws0.append([\"neg_sample_ratio\", str(NEG_SAMPLE_RATIO) if NEG_SAMPLE_RATIO is not None else \"0\"])\n",
    "ws0.append([\"neg_per_pos\", str(NEG_PER_POS) if NEG_PER_POS is not None else \"0\"])\n",
    "\n",
    "ws0.append([\"\"])\n",
    "ws0.append([\"report_folder_name\", REPORT_FOLDER_NAME])\n",
    "ws0.append([\"report_dir\", REPORT_DIR])\n",
    "\n",
    "# Sheet 2: epoch_metrics（列名+顺序对齐你CNN）\n",
    "ws1 = wb.create_sheet(\"epoch_metrics\")\n",
    "cols = [\n",
    "    \"epoch\",\"global_step\",\"loss\",\"lr\",\n",
    "    \"threshold\",\"precision\",\"recall\",\"f1\",\"acc\",\n",
    "    \"tp\",\"fp\",\"tn\",\"fn\",\n",
    "    \"pos_pred_rate\",\"avg_prob_pos\",\"avg_prob_neg\",\n",
    "    \"pr_auc_ap\",\"roc_auc\",\n",
    "    \"best_threshold_train\",\"best_f1_train\",\n",
    "    \"raw_pos_weight\",\"pos_weight\",\"weight_noncut\",\"weight_cut\"\n",
    "]\n",
    "extra_cols = [\n",
    "    \"train_pairs_epoch\",\n",
    "    \"raw_pos_weight_epoch\",\n",
    "    \"pos_weight_mode\",\n",
    "    \"pos_weight_used_epoch\",\n",
    "    \"neg_sampling_enabled\",\n",
    "    \"neg_sampling_mode\",\n",
    "    \"neg_sample_ratio\",\n",
    "    \"neg_per_pos\"\n",
    "]\n",
    "all_cols = cols + extra_cols\n",
    "\n",
    "ws1.append(all_cols)\n",
    "for r in epoch_rows:\n",
    "    row_out = []\n",
    "    for c in all_cols:\n",
    "        v = r.get(c, None)\n",
    "        # 不可用字段处理：字符串 -> unavailable；数值 -> 0\n",
    "        if v is None:\n",
    "            if c in [\"pos_weight_mode\", \"neg_sampling_mode\"]:\n",
    "                v = \"unavailable\"\n",
    "            else:\n",
    "                v = 0\n",
    "        row_out.append(v)\n",
    "    ws1.append(row_out)\n",
    "\n",
    "# Sheet 3: final_test（对齐你CNN）\n",
    "ws2 = wb.create_sheet(\"final_test\")\n",
    "ws2.append([\"metric\", \"value\"])\n",
    "ws2.append([\"threshold\", m_test[\"threshold\"]])\n",
    "ws2.append([\"precision\", m_test[\"precision\"]])\n",
    "ws2.append([\"recall\", m_test[\"recall\"]])\n",
    "ws2.append([\"f1\", m_test[\"f1\"]])\n",
    "ws2.append([\"acc\", m_test[\"acc\"]])\n",
    "ws2.append([\"tp\", m_test[\"tp\"]])\n",
    "ws2.append([\"fp\", m_test[\"fp\"]])\n",
    "ws2.append([\"tn\", m_test[\"tn\"]])\n",
    "ws2.append([\"fn\", m_test[\"fn\"]])\n",
    "ws2.append([\"pos_pred_rate\", m_test[\"pos_pred_rate\"]])\n",
    "ws2.append([\"avg_prob_pos\", m_test[\"avg_prob_pos\"]])\n",
    "ws2.append([\"avg_prob_neg\", m_test[\"avg_prob_neg\"]])\n",
    "ws2.append([\"pr_auc_ap\", ap_test])\n",
    "ws2.append([\"roc_auc\", auc_test])\n",
    "\n",
    "ws2.append([\"\"])\n",
    "ws2.append([\"classification_report\", \"\"])\n",
    "report_str = simple_classification_report(y_true_b, y_pred_b, target_names=[\"Non-cut\", \"Cut\"])\n",
    "for line in report_str.splitlines():\n",
    "    ws2.append([line, \"\"])\n",
    "\n",
    "wb.save(out_path)\n",
    "print(f\"\\nSaved metrics Excel to: {out_path}\")\n",
    "print(f\"[Report] Folder: {REPORT_DIR}\")\n",
    "\n",
    "# ===== 保存模型到同一个报告文件夹（对齐你之前的保存习惯）=====\n",
    "try:\n",
    "    ts_model = datetime.now(_TZ).strftime(\"%Y%m%d_%H%M%S\") if _TZ else datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = os.path.join(REPORT_DIR, f\"linear_model_{ts_model}.pt\")\n",
    "    ckpt_path  = os.path.join(REPORT_DIR, f\"linear_ckpt_{ts_model}.pth\")\n",
    "\n",
    "    torch.save(baseline_model.state_dict(), model_path)\n",
    "\n",
    "    ckpt = {\n",
    "        \"model_state_dict\": baseline_model.state_dict(),\n",
    "        \"model_name\": \"BoundaryLinearBaseline\",\n",
    "        \"device_saved\": str(device),\n",
    "        \"threshold_default\": float(threshold_default),\n",
    "        \"batch_size\": int(BATCH_SIZE),\n",
    "        \"report_dir\": REPORT_DIR,\n",
    "        \"report_folder_name\": REPORT_FOLDER_NAME,\n",
    "        \"epochs\": int(epochs),\n",
    "        \"pos_weight\": float(pos_weight),\n",
    "        \"raw_pos_weight\": float(raw_pos_weight) if raw_pos_weight is not None else 0.0,\n",
    "        \"saved_time\": datetime.now(_TZ).strftime(\"%Y-%m-%d %H:%M:%S %Z\") if _TZ else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    torch.save(ckpt, ckpt_path)\n",
    "\n",
    "    print(f\"[Model] Saved state_dict to: {model_path}\")\n",
    "    print(f\"[Model] Saved checkpoint to: {ckpt_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"[Model] Save failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da16983-c669-4ccd-824a-596f9607fc69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "[cut_test] Using FPS from Excel first row: 24.0\n",
      "[cut_test] Video 0 (V001.mp4): total_frames=166, cuts-1@frames=[44]\n",
      "[cut_test] Video 1 (V002.mp4): total_frames=290, cuts-1@frames=[28, 68, 100, 163, 200, 249]\n",
      "[cut_test] Video 2 (V003.mp4): total_frames=252, cuts-1@frames=[36, 152, 181, 205]\n",
      "[cut_test] Video 3 (V004.mp4): total_frames=77, cuts-1@frames=[4, 34, 68]\n",
      "[cut_test] Video 4 (V005.mp4): total_frames=100, cuts-1@frames=[5, 12, 27, 46, 80, 88]\n",
      "\n",
      "[cut_test] Generated 880 pairs: 20 cuts, 860 non-cuts\n",
      "\n",
      "[cut_test] FINAL TEST (threshold=0.5) => F1 0.4000 (P 1.0000, R 0.2500) | AP 0.9558 | AUC 0.9990 | TP 5 FP 0 TN 860 FN 15\n",
      "\n",
      "Shot Boundary Detection - Classification Report (cut_test):\n",
      "precision    recall  f1-score   support\n",
      "Non-cut     0.9829   1.0000   0.9914     860\n",
      "Cut         1.0000   0.2500   0.4000      20\n",
      "\n",
      "accuracy                        0.9830     880\n",
      "\n",
      "Saved cut_test report Excel to: movie/reports/01192309_e100_w40_linear/cut_test_report_20260119_230938.xlsx\n",
      "[Report] Folder: movie/reports/01192309_e100_w40_linear\n",
      "[Model] Saved state_dict to: movie/reports/01192309_e100_w40_linear/baseline_model_20260119_230938.pt\n",
      "[Model] Saved checkpoint to: movie/reports/01192309_e100_w40_linear/baseline_ckpt_20260119_230938.pth\n"
     ]
    }
   ],
   "source": [
    "# ============= Cell4: cut_test 测试（详细报告 + 写Excel，严格对齐“代码4.docx 里的原Cell4格式”） =============\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import platform\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo  # py>=3.9\n",
    "    _TZ = ZoneInfo(\"Asia/BeiJing\")\n",
    "except Exception:\n",
    "    _TZ = None\n",
    "\n",
    "# ===== 路径改成你的测试集 =====\n",
    "test_video_dir  = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut_test\"\n",
    "test_excel_file = f\"{PROJECT_ROOT}/{DATA_VERSION}/dataset/cut_test.xlsx\"\n",
    "\n",
    "# ===== 一些参数 =====\n",
    "threshold_default = 0.95\n",
    "batch_size = 1024\n",
    "topk_suspects = 10  # 每个视频输出 topK “最可疑的 FP / 最可疑的 FN”\n",
    "\n",
    "# ===== 输入尺寸：复用你Cell1/Cell3的 frame_size；没有就兜底 224 =====\n",
    "if \"frame_size\" in globals() and isinstance(frame_size, (tuple, list)) and len(frame_size) == 2:\n",
    "    _FRAME_SIZE = (int(frame_size[0]), int(frame_size[1]))\n",
    "else:\n",
    "    _FRAME_SIZE = (224, 224)\n",
    "\n",
    "# ===== 设备与模型 =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 兼容：baseline_model（单层）或 boundary_model（CNN）\n",
    "_model = None\n",
    "_model_name = \"unavailable\"\n",
    "if \"baseline_model\" in globals():\n",
    "    _model = baseline_model\n",
    "    _model_name = \"baseline_model\"\n",
    "elif \"boundary_model\" in globals():\n",
    "    _model = boundary_model\n",
    "    _model_name = \"boundary_model\"\n",
    "\n",
    "if _model is None:\n",
    "    raise RuntimeError(\"No model found: baseline_model / boundary_model 都不存在。请先运行你的训练Cell。\")\n",
    "\n",
    "_model = _model.to(device)\n",
    "_model.eval()\n",
    "\n",
    "# =====（如果存在你的 simple_classification_report，就复用；否则按原docx补一个最简版）=====\n",
    "if \"simple_classification_report\" not in globals():\n",
    "    def simple_classification_report(y_true, y_pred, target_names):\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        n_classes = len(target_names)\n",
    "        lines = []\n",
    "        acc = (y_true == y_pred).sum() / len(y_true) if len(y_true) > 0 else 0.0\n",
    "        lines.append(\"precision    recall  f1-score   support\")\n",
    "        for i in range(n_classes):\n",
    "            name = target_names[i]\n",
    "            true_i = (y_true == i)\n",
    "            pred_i = (y_pred == i)\n",
    "            tp = np.logical_and(true_i, pred_i).sum()\n",
    "            fp = np.logical_and(~true_i, pred_i).sum()\n",
    "            fn = np.logical_and(true_i, ~pred_i).sum()\n",
    "            support = true_i.sum()\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "            lines.append(f\"{name:10s}  {precision:0.4f}   {recall:0.4f}   {f1:0.4f}   {support:5d}\")\n",
    "        lines.append(f\"\\naccuracy                        {acc:0.4f}   {len(y_true):5d}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "# ===== 指标函数（与原docx一致风格）=====\n",
    "def _safe_div(a, b):\n",
    "    return float(a) / float(b) if b else 0.0\n",
    "\n",
    "def binary_metrics_from_probs(y_true, prob_pos, threshold=0.95):\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "    prob_pos = np.asarray(prob_pos, dtype=np.float64)\n",
    "    y_pred = (prob_pos >= threshold).astype(np.int64)\n",
    "\n",
    "    tp = int(np.sum((y_true == 1) & (y_pred == 1)))\n",
    "    fp = int(np.sum((y_true == 0) & (y_pred == 1)))\n",
    "    tn = int(np.sum((y_true == 0) & (y_pred == 0)))\n",
    "    fn = int(np.sum((y_true == 1) & (y_pred == 0)))\n",
    "\n",
    "    precision = _safe_div(tp, tp + fp)\n",
    "    recall    = _safe_div(tp, tp + fn)\n",
    "    f1        = _safe_div(2 * precision * recall, precision + recall)\n",
    "    acc       = _safe_div(tp + tn, tp + tn + fp + fn)\n",
    "    pos_pred_rate = _safe_div(tp + fp, len(y_true))\n",
    "\n",
    "    avg_prob_pos = float(np.mean(prob_pos[y_true == 1])) if np.any(y_true == 1) else 0.0\n",
    "    avg_prob_neg = float(np.mean(prob_pos[y_true == 0])) if np.any(y_true == 0) else 0.0\n",
    "\n",
    "    return {\n",
    "        \"threshold\": float(threshold),\n",
    "        \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn,\n",
    "        \"precision\": precision, \"recall\": recall, \"f1\": f1, \"acc\": acc,\n",
    "        \"pos_pred_rate\": pos_pred_rate,\n",
    "        \"avg_prob_pos\": avg_prob_pos,\n",
    "        \"avg_prob_neg\": avg_prob_neg,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "\n",
    "def average_precision_score(y_true, prob_pos):\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "    prob_pos = np.asarray(prob_pos, dtype=np.float64)\n",
    "    pos_count = int(np.sum(y_true == 1))\n",
    "    if pos_count == 0:\n",
    "        return 0.0\n",
    "    order = np.argsort(-prob_pos)\n",
    "    y_sorted = y_true[order]\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    precisions_at_hits = []\n",
    "    for i in range(len(y_sorted)):\n",
    "        if y_sorted[i] == 1:\n",
    "            tp += 1\n",
    "            precisions_at_hits.append(tp / (tp + fp))\n",
    "        else:\n",
    "            fp += 1\n",
    "    return float(np.sum(precisions_at_hits) / pos_count)\n",
    "\n",
    "def roc_auc_score_rank(y_true, prob_pos):\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "    prob_pos = np.asarray(prob_pos, dtype=np.float64)\n",
    "    n_pos = int(np.sum(y_true == 1))\n",
    "    n_neg = int(np.sum(y_true == 0))\n",
    "    if n_pos == 0 or n_neg == 0:\n",
    "        return 0.0\n",
    "\n",
    "    order = np.argsort(prob_pos)\n",
    "    ranks = np.empty_like(order, dtype=np.float64)\n",
    "    ranks[order] = np.arange(1, len(prob_pos) + 1, dtype=np.float64)\n",
    "\n",
    "    sorted_scores = prob_pos[order]\n",
    "    i = 0\n",
    "    while i < len(sorted_scores):\n",
    "        j = i\n",
    "        while j + 1 < len(sorted_scores) and sorted_scores[j + 1] == sorted_scores[i]:\n",
    "            j += 1\n",
    "        if j > i:\n",
    "            avg_rank = float(np.mean(ranks[order[i:j+1]]))\n",
    "            ranks[order[i:j+1]] = avg_rank\n",
    "        i = j + 1\n",
    "\n",
    "    sum_ranks_pos = float(np.sum(ranks[y_true == 1]))\n",
    "    auc = (sum_ranks_pos - n_pos * (n_pos + 1) / 2.0) / (n_pos * n_neg)\n",
    "    return float(auc)\n",
    "\n",
    "# ===== 读取 Excel（第一行 FPS，后面每行=一个视频的多列cut标注）=====\n",
    "wb = openpyxl.load_workbook(test_excel_file, data_only=True)\n",
    "ws = wb.active\n",
    "rows = list(ws.iter_rows(values_only=True))\n",
    "if len(rows) == 0:\n",
    "    raise RuntimeError(\"cut_test.xlsx 里没有任何行！\")\n",
    "\n",
    "fps_row = rows[0]\n",
    "\n",
    "def get_fps_from_row(r, default=24.0):\n",
    "    for cell in r:\n",
    "        if cell is None:\n",
    "            continue\n",
    "        if isinstance(cell, (int, float)):\n",
    "            return float(cell)\n",
    "        if isinstance(cell, str):\n",
    "            s = cell.strip()\n",
    "            if s == \"\" or s.lower() == \"none\":\n",
    "                continue\n",
    "            try:\n",
    "                return float(s)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return float(default)\n",
    "\n",
    "fps = get_fps_from_row(fps_row, default=24.0)\n",
    "print(f\"[cut_test] Using FPS from Excel first row: {fps}\")\n",
    "\n",
    "data_rows = rows[1:]\n",
    "\n",
    "video_files = sorted(glob.glob(f\"{test_video_dir}/V*.mp4\"))\n",
    "assert len(video_files) == len(data_rows), f\"Mismatch: videos({len(video_files)}) vs excel rows({len(data_rows)})\"\n",
    "\n",
    "def timecode_to_frame(tc, fps):\n",
    "    if tc is None:\n",
    "        return None\n",
    "    if isinstance(tc, (int, float)):\n",
    "        return int(tc)\n",
    "    if isinstance(tc, str):\n",
    "        s = tc.strip()\n",
    "        if s == \"\" or s.lower() == \"none\":\n",
    "            return None\n",
    "        if s.isdigit():\n",
    "            return int(s)\n",
    "        if \":\" in s:\n",
    "            parts = s.split(\":\")\n",
    "            try:\n",
    "                if len(parts) == 2:\n",
    "                    sec = int(parts[0])\n",
    "                    frm = int(parts[1])\n",
    "                    return int(sec * fps + frm)\n",
    "                elif len(parts) == 3:\n",
    "                    h = int(parts[0]); m = int(parts[1]); sec = int(parts[2])\n",
    "                    total_sec = h * 3600 + m * 60 + sec\n",
    "                    return int(total_sec * fps)\n",
    "                else:\n",
    "                    return None\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "# ===== 读取视频帧 + 生成 boundary_pairs_test（完全对齐原Cell4逻辑：Excel标B-start -> pair=i=B-1）=====\n",
    "video_frames = []\n",
    "boundary_pairs_test = []\n",
    "video_meta = []  # 每个视频的 meta：total_frames, gt_cut_indices, name, path\n",
    "\n",
    "for vid_idx, (video_path, row) in enumerate(zip(video_files, data_rows)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        frame_resized = cv2.resize(frame, _FRAME_SIZE)\n",
    "        frames.append(frame_resized)\n",
    "        success, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    video_frames.append(frames)\n",
    "    total_frames = len(frames)\n",
    "\n",
    "    if total_frames <= 1:\n",
    "        print(f\"[cut_test] Warning: {video_path} has {total_frames} frame(s), skip.\")\n",
    "        video_meta.append({\n",
    "            \"vid_idx\": vid_idx,\n",
    "            \"name\": os.path.basename(video_path),\n",
    "            \"path\": video_path,\n",
    "            \"total_frames\": total_frames,\n",
    "            \"gt_cut_indices\": [],\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    raw_values = list(row) if row is not None else []\n",
    "    cut_indices = []\n",
    "\n",
    "    for v in raw_values:\n",
    "        frame_idx = timecode_to_frame(v, fps)\n",
    "        if frame_idx is None:\n",
    "            continue\n",
    "\n",
    "        # Excel 标切后起始帧(B-start)，SBD 标在 (B-1,B) -> i=B-1\n",
    "        if frame_idx > 0:\n",
    "            frame_idx = frame_idx - 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        frame_idx = int(frame_idx)\n",
    "        frame_idx = max(0, min(frame_idx, total_frames - 2))\n",
    "        cut_indices.append(frame_idx)\n",
    "\n",
    "    cut_indices = sorted(set(cut_indices))\n",
    "    print(f\"[cut_test] Video {vid_idx} ({os.path.basename(video_path)}): total_frames={total_frames}, cuts-1@frames={cut_indices}\")\n",
    "\n",
    "    video_meta.append({\n",
    "        \"vid_idx\": vid_idx,\n",
    "        \"name\": os.path.basename(video_path),\n",
    "        \"path\": video_path,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"gt_cut_indices\": cut_indices,\n",
    "    })\n",
    "\n",
    "    cut_set = set(cut_indices)\n",
    "    for i in range(total_frames - 1):\n",
    "        label = 1 if i in cut_set else 0\n",
    "        boundary_pairs_test.append((vid_idx, i, label))\n",
    "\n",
    "num_pairs = len(boundary_pairs_test)\n",
    "num_cuts = sum(1 for _, _, lbl in boundary_pairs_test if lbl == 1)\n",
    "num_noncuts = num_pairs - num_cuts\n",
    "print(f\"\\n[cut_test] Generated {num_pairs} pairs: {num_cuts} cuts, {num_noncuts} non-cuts\")\n",
    "\n",
    "# ===== Dataset：9通道(frameA, frameB, diff)（对齐原Cell4）=====\n",
    "class ShotBoundaryDataset(Dataset):\n",
    "    def __init__(self, pairs, video_frames):\n",
    "        self.pairs = pairs\n",
    "        self.video_frames = video_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_idx, frame_idx, label = self.pairs[idx]\n",
    "        frameA = self.video_frames[vid_idx][frame_idx]\n",
    "        frameB = self.video_frames[vid_idx][frame_idx + 1]\n",
    "        diff = cv2.absdiff(frameA, frameB)\n",
    "\n",
    "        img_9ch = np.concatenate([frameA, frameB, diff], axis=2).astype(\"float32\") / 255.0\n",
    "        img_9ch_chw = np.transpose(img_9ch, (2, 0, 1))\n",
    "\n",
    "        img_tensor = torch.tensor(img_9ch_chw, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "test_dataset = ShotBoundaryDataset(boundary_pairs_test, video_frames)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# ===== 推理并收集：整体 + 每个pair的详细信息（对齐原Cell4）=====\n",
    "y_true, prob_pos, y_pred = [], [], []\n",
    "pair_details = []  # (vid_idx, frame_idx, gt, prob, pred)\n",
    "\n",
    "t0 = time.time()\n",
    "pair_ptr = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        bsz = labels.size(0)\n",
    "        imgs = imgs.to(device)\n",
    "        out = _model(imgs)\n",
    "\n",
    "        # 兼容 CNN logits[B,2] / baseline 单logit[B] 或 [B,1]\n",
    "        if out.dim() == 2 and out.size(1) == 2:\n",
    "            probs = torch.softmax(out, dim=1)[:, 1]\n",
    "        else:\n",
    "            probs = torch.sigmoid(out.view(-1))\n",
    "\n",
    "        pred = (probs >= threshold_default).long()\n",
    "\n",
    "        probs_np = probs.detach().cpu().numpy()\n",
    "        pred_np  = pred.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        y_true.extend(labels_np.tolist())\n",
    "        prob_pos.extend(probs_np.tolist())\n",
    "        y_pred.extend(pred_np.tolist())\n",
    "\n",
    "        for j in range(bsz):\n",
    "            vid_idx, frame_idx, gt = boundary_pairs_test[pair_ptr + j]\n",
    "            pair_details.append((vid_idx, frame_idx, int(gt), float(probs_np[j]), int(pred_np[j])))\n",
    "        pair_ptr += bsz\n",
    "\n",
    "t_infer = time.time() - t0\n",
    "\n",
    "# ===== 汇总整体指标 =====\n",
    "m = binary_metrics_from_probs(y_true, prob_pos, threshold=threshold_default)\n",
    "ap = average_precision_score(y_true, prob_pos)\n",
    "auc = roc_auc_score_rank(y_true, prob_pos)\n",
    "\n",
    "print(\"\\n[cut_test] FINAL TEST (threshold=0.5) => \"\n",
    "      f\"F1 {m['f1']:.4f} (P {m['precision']:.4f}, R {m['recall']:.4f}) | \"\n",
    "      f\"AP {ap:.4f} | AUC {auc:.4f} | \"\n",
    "      f\"TP {m['tp']} FP {m['fp']} TN {m['tn']} FN {m['fn']}\")\n",
    "\n",
    "print(\"\\nShot Boundary Detection - Classification Report (cut_test):\")\n",
    "report_str = simple_classification_report(y_true, y_pred, target_names=[\"Non-cut\", \"Cut\"])\n",
    "print(report_str)\n",
    "\n",
    "# ===== 每个视频的详细统计（对齐原Cell4：per_video + suspects_topk）=====\n",
    "per_video_pairs = {vm[\"vid_idx\"]: [] for vm in video_meta}\n",
    "for (vid_idx, frame_idx, gt, p, pred) in pair_details:\n",
    "    per_video_pairs[vid_idx].append((frame_idx, gt, p, pred))\n",
    "\n",
    "per_video_rows = []\n",
    "per_video_suspects_rows = []  # [vid, vid_idx, type, rank, frame_idx, prob_cut]\n",
    "\n",
    "for vm in video_meta:\n",
    "    vid_idx = vm[\"vid_idx\"]\n",
    "    name = vm[\"name\"]\n",
    "    total_frames = vm[\"total_frames\"]\n",
    "    gt_cuts = set(vm[\"gt_cut_indices\"])\n",
    "\n",
    "    pairs = per_video_pairs.get(vid_idx, [])\n",
    "    if not pairs:\n",
    "        per_video_rows.append({\n",
    "            \"vid\": name, \"vid_idx\": vid_idx, \"total_frames\": total_frames,\n",
    "            \"gt_cut_count\": len(gt_cuts), \"pred_cut_count\": 0,\n",
    "            \"tp\": 0, \"fp\": 0, \"fn\": len(gt_cuts),\n",
    "            \"gt_cuts\": \",\".join(map(str, sorted(gt_cuts))) if gt_cuts else \"none\",\n",
    "            \"pred_cuts\": \"none\",\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    pred_cuts = sorted({fr for (fr, gt, p, pred) in pairs if pred == 1})\n",
    "    pred_cut_set = set(pred_cuts)\n",
    "\n",
    "    tp = len(gt_cuts & pred_cut_set)\n",
    "    fp = len(pred_cut_set - gt_cuts)\n",
    "    fn = len(gt_cuts - pred_cut_set)\n",
    "\n",
    "    per_video_rows.append({\n",
    "        \"vid\": name, \"vid_idx\": vid_idx, \"total_frames\": total_frames,\n",
    "        \"gt_cut_count\": len(gt_cuts), \"pred_cut_count\": len(pred_cut_set),\n",
    "        \"tp\": tp, \"fp\": fp, \"fn\": fn,\n",
    "        \"gt_cuts\": \",\".join(map(str, sorted(gt_cuts))) if gt_cuts else \"none\",\n",
    "        \"pred_cuts\": \",\".join(map(str, pred_cuts)) if pred_cuts else \"none\",\n",
    "    })\n",
    "\n",
    "    fps_list = [(fr, p) for (fr, gt, p, pred) in pairs if gt == 0 and pred == 1]\n",
    "    fns_list = [(fr, p) for (fr, gt, p, pred) in pairs if gt == 1 and pred == 0]\n",
    "    fps_list = sorted(fps_list, key=lambda x: -x[1])[:topk_suspects]\n",
    "    fns_list = sorted(fns_list, key=lambda x: x[1])[:topk_suspects]\n",
    "\n",
    "    for rank, (fr, pp) in enumerate(fps_list, start=1):\n",
    "        per_video_suspects_rows.append([name, vid_idx, \"FP\", rank, fr, float(pp)])\n",
    "    for rank, (fr, pp) in enumerate(fns_list, start=1):\n",
    "        per_video_suspects_rows.append([name, vid_idx, \"FN\", rank, fr, float(pp)])\n",
    "\n",
    "# ===== 写入 Excel：sheet 名与结构严格对齐原Cell4 =====\n",
    "base_dir = \"movie/reports\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# 复用训练Cell3产生的报告目录；没有就按同规则新建（原Cell4就是这么做的）\n",
    "if \"REPORT_DIR\" not in globals() or \"REPORT_FOLDER_NAME\" not in globals():\n",
    "    ts_folder = datetime.now(_TZ).strftime(\"%m%d%H%M\") if _TZ else datetime.now().strftime(\"%m%d%H%M\")\n",
    "    _e = globals().get(\"epochs\", \"NA\")\n",
    "    _w = globals().get(\"pos_weight\", \"NA\")\n",
    "    REPORT_FOLDER_NAME = f\"{ts_folder}_e{_e}_w{_w}\"\n",
    "    REPORT_DIR = os.path.join(base_dir, REPORT_FOLDER_NAME)\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "ts = datetime.now(_TZ).strftime(\"%Y%m%d_%H%M%S\") if _TZ else datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(REPORT_DIR, f\"cut_test_report_{ts}.xlsx\")\n",
    "\n",
    "wb_out = openpyxl.Workbook()\n",
    "\n",
    "# Sheet: run_info（原Cell4格式）\n",
    "ws0 = wb_out.active\n",
    "ws0.title = \"run_info\"\n",
    "ws0.append([\"key\", \"value\"])\n",
    "ws0.append([\"time\", datetime.now(_TZ).strftime(\"%Y-%m-%d %H:%M:%S %Z\") if _TZ else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")])\n",
    "ws0.append([\"python_version\", platform.python_version()])\n",
    "ws0.append([\"platform\", platform.platform()])\n",
    "ws0.append([\"processor\", platform.processor()])\n",
    "ws0.append([\"torch_version\", torch.__version__])\n",
    "ws0.append([\"cuda_available\", str(torch.cuda.is_available())])\n",
    "ws0.append([\"device_used\", str(device)])\n",
    "ws0.append([\"test_video_dir\", test_video_dir])\n",
    "ws0.append([\"test_excel_file\", test_excel_file])\n",
    "ws0.append([\"fps_from_excel\", str(fps)])\n",
    "ws0.append([\"threshold_default\", str(threshold_default)])\n",
    "ws0.append([\"batch_size\", str(batch_size)])\n",
    "ws0.append([\"topk_suspects\", str(topk_suspects)])\n",
    "ws0.append([\"model_used\", _model_name])\n",
    "ws0.append([\"infer_seconds\", f\"{t_infer:.3f}\"])\n",
    "ws0.append([\"report_folder_name\", REPORT_FOLDER_NAME])\n",
    "ws0.append([\"report_dir\", REPORT_DIR])\n",
    "\n",
    "# Sheet: dataset_summary（原Cell4格式）\n",
    "ws_sum = wb_out.create_sheet(\"dataset_summary\")\n",
    "ws_sum.append([\"item\", \"value\"])\n",
    "ws_sum.append([\"num_videos\", len(video_files)])\n",
    "ws_sum.append([\"num_pairs\", num_pairs])\n",
    "ws_sum.append([\"num_cuts\", num_cuts])\n",
    "ws_sum.append([\"num_non_cuts\", num_noncuts])\n",
    "ws_sum.append([\"pos_ratio\", (num_cuts / num_pairs) if num_pairs else 0.0])\n",
    "\n",
    "ws_sum.append([\"\"])\n",
    "ws_sum.append([\"per_video_frame_stats\", \"\"])\n",
    "frames_list = [vm[\"total_frames\"] for vm in video_meta if vm[\"total_frames\"] is not None]\n",
    "if frames_list:\n",
    "    ws_sum.append([\"min_frames\", int(np.min(frames_list))])\n",
    "    ws_sum.append([\"max_frames\", int(np.max(frames_list))])\n",
    "    ws_sum.append([\"mean_frames\", float(np.mean(frames_list))])\n",
    "    ws_sum.append([\"median_frames\", float(np.median(frames_list))])\n",
    "\n",
    "# Sheet: per_video（原Cell4格式）\n",
    "ws_v = wb_out.create_sheet(\"per_video\")\n",
    "ws_v.append([\n",
    "    \"vid\", \"vid_idx\", \"total_frames\",\n",
    "    \"gt_cut_count\", \"pred_cut_count\",\n",
    "    \"tp\", \"fp\", \"fn\",\n",
    "    \"gt_cuts\", \"pred_cuts\"\n",
    "])\n",
    "for r in per_video_rows:\n",
    "    ws_v.append([\n",
    "        r[\"vid\"], r[\"vid_idx\"], r[\"total_frames\"],\n",
    "        r[\"gt_cut_count\"], r[\"pred_cut_count\"],\n",
    "        r[\"tp\"], r[\"fp\"], r[\"fn\"],\n",
    "        r[\"gt_cuts\"], r[\"pred_cuts\"]\n",
    "    ])\n",
    "\n",
    "# Sheet: suspects_topk（原Cell4格式）\n",
    "ws_sus = wb_out.create_sheet(\"suspects_topk\")\n",
    "ws_sus.append([\"vid\", \"vid_idx\", \"type\", \"rank\", \"frame_idx\", \"prob_cut\"])\n",
    "for row in per_video_suspects_rows:\n",
    "    ws_sus.append(row)\n",
    "\n",
    "# Sheet: final_test（原Cell4格式）\n",
    "ws2 = wb_out.create_sheet(\"final_test\")\n",
    "ws2.append([\"metric\", \"value\"])\n",
    "ws2.append([\"threshold\", m[\"threshold\"]])\n",
    "ws2.append([\"precision\", m[\"precision\"]])\n",
    "ws2.append([\"recall\", m[\"recall\"]])\n",
    "ws2.append([\"f1\", m[\"f1\"]])\n",
    "ws2.append([\"acc\", m[\"acc\"]])\n",
    "ws2.append([\"tp\", m[\"tp\"]])\n",
    "ws2.append([\"fp\", m[\"fp\"]])\n",
    "ws2.append([\"tn\", m[\"tn\"]])\n",
    "ws2.append([\"fn\", m[\"fn\"]])\n",
    "ws2.append([\"pos_pred_rate\", m[\"pos_pred_rate\"]])\n",
    "ws2.append([\"avg_prob_pos\", m[\"avg_prob_pos\"]])\n",
    "ws2.append([\"avg_prob_neg\", m[\"avg_prob_neg\"]])\n",
    "ws2.append([\"pr_auc_ap\", ap])\n",
    "ws2.append([\"roc_auc\", auc])\n",
    "\n",
    "# Sheet: classification_report（原Cell4格式：逐行写文本）\n",
    "ws_rep = wb_out.create_sheet(\"classification_report\")\n",
    "ws_rep.append([\"text\"])\n",
    "for line in report_str.splitlines():\n",
    "    ws_rep.append([line])\n",
    "\n",
    "wb_out.save(out_path)\n",
    "print(f\"\\nSaved cut_test report Excel to: {out_path}\")\n",
    "print(f\"[Report] Folder: {REPORT_DIR}\")\n",
    "\n",
    "# ===== 保存模型到同一个报告文件夹（对齐你原Cell4风格：state_dict + ckpt）=====\n",
    "try:\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "    ts_model = datetime.now(_TZ).strftime(\"%Y%m%d_%H%M%S\") if _TZ else datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 文件名保持原风格，但根据模型类型区分一下（不影响你的系统读取Excel）\n",
    "    if _model_name == \"baseline_model\":\n",
    "        model_path = os.path.join(REPORT_DIR, f\"baseline_model_{ts_model}.pt\")\n",
    "        ckpt_path  = os.path.join(REPORT_DIR, f\"baseline_ckpt_{ts_model}.pth\")\n",
    "    else:\n",
    "        model_path = os.path.join(REPORT_DIR, f\"boundary_model_{ts_model}.pt\")\n",
    "        ckpt_path  = os.path.join(REPORT_DIR, f\"boundary_ckpt_{ts_model}.pth\")\n",
    "\n",
    "    torch.save(_model.state_dict(), model_path)\n",
    "\n",
    "    ckpt = {\n",
    "        \"model_state_dict\": _model.state_dict(),\n",
    "        \"model_used\": _model_name,\n",
    "        \"device_saved\": str(device),\n",
    "        \"fps_from_excel\": float(fps),\n",
    "        \"threshold_default\": float(threshold_default),\n",
    "        \"batch_size\": int(batch_size),\n",
    "        \"frame_size\": tuple(_FRAME_SIZE),\n",
    "        \"report_dir\": REPORT_DIR,\n",
    "        \"report_folder_name\": REPORT_FOLDER_NAME,\n",
    "        \"epochs\": globals().get(\"epochs\", None),\n",
    "        \"pos_weight\": globals().get(\"pos_weight\", None),\n",
    "        \"build_id\": globals().get(\"BUILD_ID\", None),\n",
    "        \"saved_time\": datetime.now(_TZ).strftime(\"%Y-%m-%d %H:%M:%S %Z\") if _TZ else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    torch.save(ckpt, ckpt_path)\n",
    "\n",
    "    print(f\"[Model] Saved state_dict to: {model_path}\")\n",
    "    print(f\"[Model] Saved checkpoint to: {ckpt_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[Model] Save failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
